{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c16e6774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 1: Imports\n",
    "# ============================================================\n",
    "import os\n",
    "from align_test.alignment import LinguisticAlignment\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a49069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created/verified: ./test_alignment_results\n",
      "✓ Created/verified: ./test_baseline_results\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Configure Directories\n",
    "# ============================================================\n",
    "\n",
    "# INPUT DIRECTORIES (from preprocessing notebook)\n",
    "# These should contain the preprocessed .txt files\n",
    "INPUT_DIR_BASIC = './test_output_basic'      # NLTK-only preprocessing\n",
    "INPUT_DIR_SPACY = './test_output_spacy'      # NLTK + spaCy preprocessing\n",
    "INPUT_DIR_STANFORD = './test_output_stanford' # NLTK + Stanford preprocessing (optional)\n",
    "\n",
    "# OUTPUT DIRECTORIES (for alignment results)\n",
    "OUTPUT_DIR_ALIGNMENT = './test_alignment_results'\n",
    "OUTPUT_DIR_BASELINE = './test_baseline_results'\n",
    "\n",
    "# Create output directories\n",
    "for dir_path in [OUTPUT_DIR_ALIGNMENT, OUTPUT_DIR_BASELINE]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"✓ Created/verified: {dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2fd97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing LexicalSyntacticAlignment analyzer...\n",
      "✓ Analyzer initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 3: Initialize Analyzer\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nInitializing LexicalSyntacticAlignment analyzer...\")\n",
    "\n",
    "analyzer_lexsyn = LinguisticAlignment(\n",
    "    alignment_type=\"lexsyn\"\n",
    "    # Note: cache_dir not needed for lexsyn (only for FastText/BERT)\n",
    ")\n",
    "\n",
    "print(\"✓ Analyzer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cf3c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANALYSIS 1: NLTK Tags Only\n",
      "============================================================\n",
      "ANALYZE_FOLDER: Processing data from folder: ./test_output_basic with lag=1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LexicalSyntacticAlignment' object has no attribute 'analyze_folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mANALYSIS 1: NLTK Tags Only\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m results_lexsyn_nltk = \u001b[43manalyzer_lexsyn\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze_folder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINPUT_DIR_BASIC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTPUT_DIR_ALIGNMENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlag\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_ngram\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_duplicates\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_additional_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# NLTK tags only\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✓ Analysis complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Total utterance pairs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results_lexsyn_nltk)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Github-Projects/llm-linguistic-alignment/src/align_test/alignment.py:93\u001b[39m, in \u001b[36mLinguisticAlignment.analyze_folder\u001b[39m\u001b[34m(self, folder_path, output_directory, file_pattern, lag, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m filtered_kwargs = \u001b[38;5;28mself\u001b[39m._filter_kwargs_for_analyzer(analyzer_type, kwargs)\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Run analysis with filtered parameters \u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Important: Don't provide output_directory here to prevent duplicate files\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m analyzer_results = \u001b[43manalyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze_folder\u001b[49m(\n\u001b[32m     94\u001b[39m     folder_path=folder_path,\n\u001b[32m     95\u001b[39m     output_directory=\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Don't save intermediate results\u001b[39;00m\n\u001b[32m     96\u001b[39m     file_pattern=file_pattern,\n\u001b[32m     97\u001b[39m     **filtered_kwargs\n\u001b[32m     98\u001b[39m )\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[32m    101\u001b[39m results[analyzer_type] = analyzer_results\n",
      "\u001b[31mAttributeError\u001b[39m: 'LexicalSyntacticAlignment' object has no attribute 'analyze_folder'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 4: Analyze NLTK-Only Preprocessing\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS 1: NLTK Tags Only\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_lexsyn_nltk = analyzer_lexsyn.analyze_folder(\n",
    "    folder_path=INPUT_DIR_BASIC,\n",
    "    output_directory=OUTPUT_DIR_ALIGNMENT,\n",
    "    lag=1,\n",
    "    max_ngram=2,\n",
    "    ignore_duplicates=True,\n",
    "    add_additional_tags=False  # NLTK tags only\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Analysis complete!\")\n",
    "print(f\"  Total utterance pairs: {len(results_lexsyn_nltk)}\")\n",
    "print(f\"  Columns: {len(results_lexsyn_nltk.columns)}\")\n",
    "print(f\"\\nResults saved to: {OUTPUT_DIR_ALIGNMENT}/lexsyn/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
