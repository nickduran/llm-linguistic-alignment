{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Suite for Refactored `prepare_transcripts.py`\n",
    "\n",
    "This notebook tests the refactored preprocessing module with CHILDES sample data and verifies compatibility with alignment analysis scripts.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you've:\n",
    "1. Installed the package in editable mode: `pip install -e .`\n",
    "2. Installed spaCy: `pip install spacy` [NOTE: is this necessary?]\n",
    "3. Downloaded spaCy model: `python -m spacy download en_core_web_sm` [NOTE: is this necessary?]\n",
    "\n",
    "## Data Location\n",
    "\n",
    "Test files: `/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/src/align_test/data/CHILDES/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Import Libraries and Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Import the refactored preprocessing module\n",
    "from align_test.prepare_transcripts_refactored import prepare_transcripts\n",
    "\n",
    "print(\"âœ“ Imports successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created directory: ./test_output_basic\n",
      "âœ“ Created directory: ./test_output_spacy\n",
      "âœ“ Created directory: ./test_alignment_results\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION: Set your data directories\n",
    "# ============================================================\n",
    "\n",
    "# Input: CHILDES data directory\n",
    "CHILDES_DATA_DIR = '/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/src/align_test/data/CHILDES/'\n",
    "\n",
    "# Output: Test output directories\n",
    "OUTPUT_DIR_BASIC = './test_output_basic'\n",
    "OUTPUT_DIR_SPACY = './test_output_spacy'\n",
    "OUTPUT_DIR_ALIGNMENT = './test_alignment_results'\n",
    "\n",
    "# Create output directories\n",
    "for dir_path in [OUTPUT_DIR_BASIC, OUTPUT_DIR_SPACY, OUTPUT_DIR_ALIGNMENT]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"âœ“ Created directory: {dir_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify Input Data\n",
    "\n",
    "Check that the CHILDES directory exists and contains our test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHILDES Directory: /Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/src/align_test/data/CHILDES/\n",
      "Exists: True\n",
      "\n",
      "âœ“ Found 20 .txt files:\n",
      "  - time197-cond1.txt (4.4 KB)\n",
      "  - time202-cond1.txt (6.2 KB)\n",
      "  - time191-cond1.txt (5.5 KB)\n",
      "  - time209-cond1.txt (6.4 KB)\n",
      "  - time210-cond1.txt (5.5 KB)\n",
      "  - time204-cond1.txt (8.8 KB)\n",
      "  - time196-cond1.txt (4.3 KB)\n",
      "  - time203-cond1.txt (5.3 KB)\n",
      "  - time208-cond1.txt (6.5 KB)\n",
      "  - time205-cond1.txt (7.5 KB)\n",
      "  - time195-cond1.txt (5.6 KB)\n",
      "  - time198-cond1.txt (5.3 KB)\n",
      "  - time200-cond1.txt (5.5 KB)\n",
      "  - time193-cond1.txt (5.7 KB)\n",
      "  - time206-cond1.txt (6.2 KB)\n",
      "  - time194-cond1.txt (5.3 KB)\n",
      "  - time199-cond1.txt (5.9 KB)\n",
      "  - time201-cond1.txt (5.6 KB)\n",
      "  - time192-cond1.txt (4.1 KB)\n",
      "  - time207-cond1.txt (6.5 KB)\n"
     ]
    }
   ],
   "source": [
    "# Check if CHILDES directory exists\n",
    "print(f\"CHILDES Directory: {CHILDES_DATA_DIR}\")\n",
    "print(f\"Exists: {os.path.exists(CHILDES_DATA_DIR)}\")\n",
    "\n",
    "if not os.path.exists(CHILDES_DATA_DIR):\n",
    "    print(\"\\nâœ— Directory not found! Please update CHILDES_DATA_DIR above.\")\n",
    "else:\n",
    "    # List files in directory\n",
    "    files = [f for f in os.listdir(CHILDES_DATA_DIR) if f.endswith('.txt')]\n",
    "    print(f\"\\nâœ“ Found {len(files)} .txt files:\")\n",
    "    for f in files:\n",
    "        file_path = os.path.join(CHILDES_DATA_DIR, f)\n",
    "        size_kb = os.path.getsize(file_path) / 1024\n",
    "        print(f\"  - {f} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inspect Raw Input Files\n",
    "\n",
    "Let's look at the structure of the raw input files before preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: time200-cond1.txt\n",
      "\n",
      "Columns: ['participant', 'content']\n",
      "Rows: 134\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cgv</td>\n",
       "      <td>well hurry Abe it's time to eat are you ready.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kid</td>\n",
       "      <td>is it time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cgv</td>\n",
       "      <td>yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kid</td>\n",
       "      <td>I'm almost done okay Mom now you can come over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cgv</td>\n",
       "      <td>okay.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant                                            content\n",
       "0         cgv     well hurry Abe it's time to eat are you ready.\n",
       "1         kid                                        is it time.\n",
       "2         cgv                                              yeah.\n",
       "3         kid  I'm almost done okay Mom now you can come over...\n",
       "4         cgv                                              okay."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and display a sample input file\n",
    "sample_file = os.path.join(CHILDES_DATA_DIR, 'time200-cond1.txt')\n",
    "\n",
    "print(f\"Reading: {os.path.basename(sample_file)}\\n\")\n",
    "\n",
    "raw_df = pd.read_csv(sample_file, sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(f\"Columns: {raw_df.columns.tolist()}\")\n",
    "print(f\"Rows: {len(raw_df)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample utterances:\n",
      "\n",
      "cgv: well hurry Abe it's time to eat are you ready.\n",
      "kid: is it time.\n",
      "cgv: yeah.\n",
      "kid: I'm almost done okay Mom now you can come over here and look.\n",
      "cgv: okay.\n"
     ]
    }
   ],
   "source": [
    "# Show some sample content\n",
    "print(\"Sample utterances:\\n\")\n",
    "for i in range(min(5, len(raw_df))):\n",
    "    print(f\"{raw_df['participant'].iloc[i]}: {raw_df['content'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 1: Basic Preprocessing (NLTK Only)\n",
    "\n",
    "Test preprocessing with default NLTK POS tagger (fastest option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Basic Preprocessing (NLTK only)\n",
      "============================================================\n",
      "Downloading required NLTK resources...\n",
      "  - Downloading wordnet...\n",
      "    âœ“ wordnet downloaded successfully\n",
      "  - Downloading omw-1.4...\n",
      "    âœ“ omw-1.4 downloaded successfully\n",
      "NLTK resources ready!\n",
      "\n",
      "\n",
      "Found 20 files to process\n",
      "Output directory: ./test_output_basic\n",
      "\n",
      "============================================================\n",
      "Processing: time197-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time197-cond1.txt\n",
      "     Rows: 76\n",
      "============================================================\n",
      "Processing: time202-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time202-cond1.txt\n",
      "     Rows: 92\n",
      "============================================================\n",
      "Processing: time191-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time191-cond1.txt\n",
      "     Rows: 99\n",
      "============================================================\n",
      "Processing: time209-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time209-cond1.txt\n",
      "     Rows: 98\n",
      "============================================================\n",
      "Processing: time210-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time210-cond1.txt\n",
      "     Rows: 100\n",
      "============================================================\n",
      "Processing: time204-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time204-cond1.txt\n",
      "     Rows: 143\n",
      "============================================================\n",
      "Processing: time196-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time196-cond1.txt\n",
      "     Rows: 66\n",
      "============================================================\n",
      "Processing: time203-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time203-cond1.txt\n",
      "     Rows: 90\n",
      "============================================================\n",
      "Processing: time208-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time208-cond1.txt\n",
      "     Rows: 86\n",
      "============================================================\n",
      "Processing: time205-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time205-cond1.txt\n",
      "     Rows: 106\n",
      "============================================================\n",
      "Processing: time195-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time195-cond1.txt\n",
      "     Rows: 90\n",
      "============================================================\n",
      "Processing: time198-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time198-cond1.txt\n",
      "     Rows: 89\n",
      "============================================================\n",
      "Processing: time200-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time200-cond1.txt\n",
      "     Rows: 78\n",
      "============================================================\n",
      "Processing: time193-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time193-cond1.txt\n",
      "     Rows: 95\n",
      "============================================================\n",
      "Processing: time206-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time206-cond1.txt\n",
      "     Rows: 97\n",
      "============================================================\n",
      "Processing: time194-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time194-cond1.txt\n",
      "     Rows: 77\n",
      "============================================================\n",
      "Processing: time199-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time199-cond1.txt\n",
      "     Rows: 87\n",
      "============================================================\n",
      "Processing: time201-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time201-cond1.txt\n",
      "     Rows: 90\n",
      "============================================================\n",
      "Processing: time192-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time192-cond1.txt\n",
      "     Rows: 67\n",
      "============================================================\n",
      "Processing: time207-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "  6. Saved: time207-cond1.txt\n",
      "     Rows: 106\n",
      "\n",
      "============================================================\n",
      "Saved concatenated dataframe: align_concatenated_dataframe.txt\n",
      "Total rows: 1832\n",
      "============================================================\n",
      "\n",
      "Processing complete!\n",
      "\n",
      "Summary:\n",
      "  - Files processed: 20\n",
      "  - Total utterances: 1832\n",
      "  - Output directory: ./test_output_basic\n",
      "\n",
      "âœ“ Preprocessing complete!\n",
      "Total utterances processed: 1832\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 1: Basic Preprocessing (NLTK only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run preprocessing with minimal options\n",
    "results_basic = prepare_transcripts(\n",
    "    input_files=CHILDES_DATA_DIR,\n",
    "    output_file_directory=OUTPUT_DIR_BASIC,\n",
    "    run_spell_check=False,  # Disable for faster testing\n",
    "    minwords=2,\n",
    "    add_stanford_tags=False,  # NLTK only\n",
    "    input_as_directory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Preprocessing complete!\")\n",
    "print(f\"Total utterances processed: {len(results_basic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output columns:\n",
      "  - participant\n",
      "  - content\n",
      "  - token\n",
      "  - lemma\n",
      "  - tagged_token\n",
      "  - tagged_lemma\n",
      "  - file\n",
      "\n",
      "DataFrame shape: (1832, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>content</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tagged_token</th>\n",
       "      <th>tagged_lemma</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cgv</td>\n",
       "      <td>that was fun</td>\n",
       "      <td>['that', 'was', 'fun']</td>\n",
       "      <td>['that', 'be', 'fun']</td>\n",
       "      <td>[('that', 'DT'), ('was', 'VBD'), ('fun', 'NN')]</td>\n",
       "      <td>[('that', 'DT'), ('be', 'VB'), ('fun', 'NN')]</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kid</td>\n",
       "      <td>dad you should have climbed the cliffs with us</td>\n",
       "      <td>['dad', 'you', 'should', 'have', 'climbed', 't...</td>\n",
       "      <td>['dad', 'you', 'should', 'have', 'climb', 'the...</td>\n",
       "      <td>[('dad', 'NN'), ('you', 'PRP'), ('should', 'MD...</td>\n",
       "      <td>[('dad', 'NN'), ('you', 'PRP'), ('should', 'MD...</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cgv</td>\n",
       "      <td>next time i will</td>\n",
       "      <td>['next', 'time', 'i', 'will']</td>\n",
       "      <td>['next', 'time', 'i', 'will']</td>\n",
       "      <td>[('next', 'JJ'), ('time', 'NN'), ('i', 'NN'), ...</td>\n",
       "      <td>[('next', 'JJ'), ('time', 'NN'), ('i', 'NN'), ...</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant                                         content  \\\n",
       "0         cgv                                    that was fun   \n",
       "1         kid  dad you should have climbed the cliffs with us   \n",
       "2         cgv                                next time i will   \n",
       "\n",
       "                                               token  \\\n",
       "0                             ['that', 'was', 'fun']   \n",
       "1  ['dad', 'you', 'should', 'have', 'climbed', 't...   \n",
       "2                      ['next', 'time', 'i', 'will']   \n",
       "\n",
       "                                               lemma  \\\n",
       "0                              ['that', 'be', 'fun']   \n",
       "1  ['dad', 'you', 'should', 'have', 'climb', 'the...   \n",
       "2                      ['next', 'time', 'i', 'will']   \n",
       "\n",
       "                                        tagged_token  \\\n",
       "0    [('that', 'DT'), ('was', 'VBD'), ('fun', 'NN')]   \n",
       "1  [('dad', 'NN'), ('you', 'PRP'), ('should', 'MD...   \n",
       "2  [('next', 'JJ'), ('time', 'NN'), ('i', 'NN'), ...   \n",
       "\n",
       "                                        tagged_lemma               file  \n",
       "0      [('that', 'DT'), ('be', 'VB'), ('fun', 'NN')]  time197-cond1.txt  \n",
       "1  [('dad', 'NN'), ('you', 'PRP'), ('should', 'MD...  time197-cond1.txt  \n",
       "2  [('next', 'JJ'), ('time', 'NN'), ('i', 'NN'), ...  time197-cond1.txt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the output\n",
    "print(\"Output columns:\")\n",
    "for col in results_basic.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nDataFrame shape: {results_basic.shape}\")\n",
    "results_basic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed utterance:\n",
      "\n",
      "Participant: cgv\n",
      "Content: that was fun\n",
      "\n",
      "Token (string): ['that', 'was', 'fun']...\n",
      "Type: <class 'str'>\n",
      "\n",
      "Token (parsed): ['that', 'was', 'fun']\n",
      "Type after parsing: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Examine a single row in detail\n",
    "print(\"Sample processed utterance:\\n\")\n",
    "sample_row = results_basic.iloc[0]\n",
    "\n",
    "print(f\"Participant: {sample_row['participant']}\")\n",
    "print(f\"Content: {sample_row['content']}\")\n",
    "print(f\"\\nToken (string): {sample_row['token'][:100]}...\")\n",
    "print(f\"Type: {type(sample_row['token'])}\")\n",
    "\n",
    "# Parse and display\n",
    "tokens = ast.literal_eval(sample_row['token'])\n",
    "print(f\"\\nToken (parsed): {tokens}\")\n",
    "print(f\"Type after parsing: {type(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Output Format\n",
    "\n",
    "Check that the output format is compatible with alignment analysis scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files created: ['time197-cond1.txt', 'time202-cond1.txt', 'time191-cond1.txt', 'time209-cond1.txt', 'time210-cond1.txt', 'time204-cond1.txt', 'time192-cond1-bs.txt', 'time196-cond1.txt', 'time203-cond1.txt', 'time208-cond1.txt', 'time205-cond1.txt', 'time195-cond1.txt', 'time198-cond1.txt', 'time200-cond1.txt', 'time193-cond1.txt', 'time206-cond1.txt', 'time194-cond1.txt', 'time199-cond1.txt', 'time201-cond1.txt', 'time192-cond1.txt', 'time207-cond1.txt']\n",
      "\n",
      "Loading: time197-cond1.txt\n",
      "Rows loaded: 76\n",
      "Columns: ['participant', 'content', 'token', 'lemma', 'tagged_token', 'tagged_lemma', 'file']\n"
     ]
    }
   ],
   "source": [
    "# Load one of the saved output files\n",
    "output_files = [f for f in os.listdir(OUTPUT_DIR_BASIC) \n",
    "                if f.endswith('.txt') and 'concatenated' not in f]\n",
    "\n",
    "print(f\"Output files created: {output_files}\")\n",
    "\n",
    "# Load the first file\n",
    "test_file_path = os.path.join(OUTPUT_DIR_BASIC, output_files[0])\n",
    "print(f\"\\nLoading: {output_files[0]}\")\n",
    "\n",
    "test_df = pd.read_csv(test_file_path, sep='\\t', encoding='utf-8')\n",
    "print(f\"Rows loaded: {len(test_df)}\")\n",
    "print(f\"Columns: {test_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Required Columns\n",
      "----------------------------------------\n",
      "âœ“ participant\n",
      "âœ“ content\n",
      "âœ“ token\n",
      "âœ“ lemma\n",
      "âœ“ tagged_token\n",
      "âœ“ tagged_lemma\n",
      "âœ“ file\n",
      "\n",
      "Result: âœ“ PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Verify all columns are present\n",
    "required_cols = ['participant', 'content', 'token', 'lemma', 'tagged_token', 'tagged_lemma', 'file']\n",
    "\n",
    "print(\"Test 1: Required Columns\")\n",
    "print(\"-\" * 40)\n",
    "for col in required_cols:\n",
    "    present = col in test_df.columns\n",
    "    status = \"âœ“\" if present else \"âœ—\"\n",
    "    print(f\"{status} {col}\")\n",
    "\n",
    "all_present = all(col in test_df.columns for col in required_cols)\n",
    "print(f\"\\nResult: {'âœ“ PASSED' if all_present else 'âœ— FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2: Data Types (should be strings)\n",
      "----------------------------------------\n",
      "âœ“ token: str\n",
      "âœ“ lemma: str\n",
      "âœ“ tagged_token: str\n",
      "âœ“ tagged_lemma: str\n",
      "\n",
      "Result: âœ“ PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Verify data types (should be strings)\n",
    "list_columns = ['token', 'lemma', 'tagged_token', 'tagged_lemma']\n",
    "\n",
    "print(\"Test 2: Data Types (should be strings)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "all_strings = True\n",
    "for col in list_columns:\n",
    "    if col in test_df.columns:\n",
    "        first_val = test_df[col].iloc[0]\n",
    "        is_string = isinstance(first_val, str)\n",
    "        status = \"âœ“\" if is_string else \"âœ—\"\n",
    "        print(f\"{status} {col}: {type(first_val).__name__}\")\n",
    "        if not is_string:\n",
    "            all_strings = False\n",
    "\n",
    "print(f\"\\nResult: {'âœ“ PASSED' if all_strings else 'âœ— FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3: ast.literal_eval Compatibility\n",
      "----------------------------------------\n",
      "âœ“ token: Parses to list\n",
      "  Sample: ['that', 'was', 'fun']...\n",
      "âœ“ lemma: Parses to list\n",
      "  Sample: ['that', 'be', 'fun']...\n",
      "âœ“ tagged_token: Parses to list\n",
      "  Sample: [('that', 'DT'), ('was', 'VBD'), ('fun', 'NN')]...\n",
      "âœ“ tagged_lemma: Parses to list\n",
      "  Sample: [('that', 'DT'), ('be', 'VB'), ('fun', 'NN')]...\n",
      "\n",
      "Result: âœ“ PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Verify ast.literal_eval compatibility\n",
    "print(\"Test 3: ast.literal_eval Compatibility\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "all_parseable = True\n",
    "for col in list_columns:\n",
    "    if col in test_df.columns:\n",
    "        try:\n",
    "            parsed = ast.literal_eval(test_df[col].iloc[0])\n",
    "            print(f\"âœ“ {col}: Parses to {type(parsed).__name__}\")\n",
    "            print(f\"  Sample: {str(parsed)[:60]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— {col}: Parse failed - {e}\")\n",
    "            all_parseable = False\n",
    "\n",
    "print(f\"\\nResult: {'âœ“ PASSED' if all_parseable else 'âœ— FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4: POS Tag Format\n",
      "----------------------------------------\n",
      "âœ“ tagged_token: Correct format\n",
      "  Sample: ('that', 'DT') (word, POS)\n",
      "âœ“ tagged_lemma: Correct format\n",
      "  Sample: ('that', 'DT') (word, POS)\n",
      "\n",
      "Result: âœ“ PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Verify POS tag tuple format\n",
    "print(\"Test 4: POS Tag Format\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "correct_format = True\n",
    "for col in ['tagged_token', 'tagged_lemma']:\n",
    "    if col in test_df.columns:\n",
    "        try:\n",
    "            parsed = ast.literal_eval(test_df[col].iloc[0])\n",
    "            if parsed:\n",
    "                is_tuple = isinstance(parsed[0], tuple)\n",
    "                correct_length = len(parsed[0]) == 2 if is_tuple else False\n",
    "                \n",
    "                if is_tuple and correct_length:\n",
    "                    print(f\"âœ“ {col}: Correct format\")\n",
    "                    print(f\"  Sample: {parsed[0]} (word, POS)\")\n",
    "                else:\n",
    "                    print(f\"âœ— {col}: Incorrect format\")\n",
    "                    correct_format = False\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— {col}: Format check failed - {e}\")\n",
    "            correct_format = False\n",
    "\n",
    "print(f\"\\nResult: {'âœ“ PASSED' if correct_format else 'âœ— FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 1 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1 SUMMARY: Basic Preprocessing\n",
      "============================================================\n",
      "\n",
      "âœ“ TEST 1 PASSED: Basic preprocessing works correctly!\n",
      "\n",
      "Output format is compatible with alignment analysis.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 1 SUMMARY: Basic Preprocessing\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test1_passed = all_present and all_strings and all_parseable and correct_format\n",
    "\n",
    "if test1_passed:\n",
    "    print(\"\\nâœ“ TEST 1 PASSED: Basic preprocessing works correctly!\")\n",
    "    print(\"\\nOutput format is compatible with alignment analysis.\")\n",
    "else:\n",
    "    print(\"\\nâœ— TEST 1 FAILED: Some checks did not pass.\")\n",
    "    print(\"Please review the test results above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 2: Preprocessing with spaCy\n",
    "\n",
    "Test preprocessing with spaCy POS tagger (100x faster than Stanford)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ spaCy is installed\n",
      "Note: Model will be auto-downloaded by prepare_transcripts() if needed\n"
     ]
    }
   ],
   "source": [
    "# Check if spaCy is available\n",
    "try:\n",
    "    import spacy\n",
    "    print(\"âœ“ spaCy is installed\")\n",
    "    print(\"Note: Model will be auto-downloaded by prepare_transcripts() if needed\")\n",
    "    spacy_available = True\n",
    "except ImportError:\n",
    "    print(\"âœ— spaCy not installed\")\n",
    "    print(\"Install with: pip install spacy\")\n",
    "    print(\"Will skip spaCy tests\")\n",
    "    spacy_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if spaCy is available\n",
    "if spacy_available:\n",
    "    print(\"=\"*60)\n",
    "    print(\"TEST 2: Preprocessing with spaCy\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Run preprocessing with spaCy\n",
    "    results_spacy = prepare_transcripts(\n",
    "        input_files=CHILDES_DATA_DIR,\n",
    "        output_file_directory=OUTPUT_DIR_SPACY,\n",
    "        run_spell_check=False,\n",
    "        minwords=2,\n",
    "        add_stanford_tags=True,\n",
    "        stanford_tagger_type='spacy',  # Use spaCy\n",
    "        input_as_directory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ“ Preprocessing with spaCy complete!\")\n",
    "    print(f\"Total utterances processed: {len(results_spacy)}\")\n",
    "else:\n",
    "    print(\"\\nSkipping spaCy test (spaCy not available)\")\n",
    "    results_spacy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output columns:\n",
      "  - participant\n",
      "  - content\n",
      "  - token\n",
      "  - lemma\n",
      "  - tagged_token\n",
      "  - tagged_lemma\n",
      "  - tagged_stan_token\n",
      "  - tagged_stan_lemma\n",
      "  - file\n",
      "\n",
      "âœ“ spaCy tagging columns present (tagged_stan_token, tagged_stan_lemma)\n",
      "\n",
      "Sample spaCy tags:\n",
      "  1. ('that', 'DT')\n",
      "  2. ('was', 'VBD')\n",
      "  3. ('fun', 'JJ')\n"
     ]
    }
   ],
   "source": [
    "# Examine spaCy output (if available)\n",
    "if results_spacy is not None:\n",
    "    print(\"Output columns:\")\n",
    "    for col in results_spacy.columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    # Check for spaCy-specific columns\n",
    "    has_spacy_cols = 'tagged_stan_token' in results_spacy.columns and 'tagged_stan_lemma' in results_spacy.columns\n",
    "    \n",
    "    if has_spacy_cols:\n",
    "        print(\"\\nâœ“ spaCy tagging columns present (tagged_stan_token, tagged_stan_lemma)\")\n",
    "        \n",
    "        # Show sample spaCy tags\n",
    "        sample_spacy_tag = ast.literal_eval(results_spacy['tagged_stan_token'].iloc[0])\n",
    "        print(f\"\\nSample spaCy tags:\")\n",
    "        for i, (word, tag) in enumerate(sample_spacy_tag[:5]):\n",
    "            print(f\"  {i+1}. ('{word}', '{tag}')\")\n",
    "    else:\n",
    "        print(\"\\nâœ— spaCy tagging columns missing!\")\n",
    "    \n",
    "    results_spacy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: NLTK vs spaCy POS Tags\n",
      "============================================================\n",
      "Utterance: that was fun\n",
      "\n",
      "Word            NLTK Tag   spaCy Tag  Same?     \n",
      "--------------------------------------------------\n",
      "that            DT         DT         âœ“         \n",
      "was             VBD        VBD        âœ“         \n",
      "fun             NN         JJ         âœ—         \n",
      "\n",
      "Agreement: 2/3 (66.7%)\n"
     ]
    }
   ],
   "source": [
    "# Compare NLTK tags vs spaCy tags for same utterance\n",
    "if results_spacy is not None:\n",
    "    print(\"Comparison: NLTK vs spaCy POS Tags\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sample_row = results_spacy.iloc[0]\n",
    "    \n",
    "    nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "    spacy_tags = ast.literal_eval(sample_row['tagged_stan_token'])\n",
    "    \n",
    "    print(f\"Utterance: {sample_row['content']}\\n\")\n",
    "    print(f\"{'Word':<15} {'NLTK Tag':<10} {'spaCy Tag':<10} {'Same?':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for (word_n, tag_n), (word_s, tag_s) in zip(nltk_tags, spacy_tags):\n",
    "        same = \"âœ“\" if tag_n == tag_s else \"âœ—\"\n",
    "        print(f\"{word_n:<15} {tag_n:<10} {tag_s:<10} {same:<10}\")\n",
    "    \n",
    "    # Calculate agreement\n",
    "    agreements = sum(1 for (_, t1), (_, t2) in zip(nltk_tags, spacy_tags) if t1 == t2)\n",
    "    total = len(nltk_tags)\n",
    "    agreement_pct = (agreements / total * 100) if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nAgreement: {agreements}/{total} ({agreement_pct:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 2 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPREHENSIVE COMPARISON: NLTK vs spaCy POS Tags\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERALL STATISTICS:\n",
      "   Total tokens compared: 21927\n",
      "   Agreements: 17950\n",
      "   Disagreements: 3977\n",
      "   Overall Agreement: 81.9%\n",
      "\n",
      "   Per-utterance agreement:\n",
      "      Mean: 81.5%\n",
      "      Median: 83.3%\n",
      "      Min: 0.0%\n",
      "      Max: 100.0%\n",
      "\n",
      "============================================================\n",
      "DETAILED EXAMPLES (First 3 utterances with >5 words)\n",
      "============================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: dad you should have climbed the cliffs with us\n",
      "\n",
      "Word            NLTK       spaCy      Match   \n",
      "------------------------------------------------\n",
      "dad             NN         NN         âœ“       \n",
      "you             PRP        PRP        âœ“       \n",
      "should          MD         MD         âœ“       \n",
      "have            VB         VB         âœ“       \n",
      "climbed         VBD        VBN        âœ—       \n",
      "the             DT         DT         âœ“       \n",
      "cliffs          NNS        NNS        âœ“       \n",
      "with            IN         IN         âœ“       \n",
      "us              PRP        PRP        âœ“       \n",
      "\n",
      "Agreement: 8/9 (88.9%)\n",
      "Disagreements: 1\n",
      "  â€¢ 'climbed': NLTK=VBD, spaCy=VBN\n",
      "\n",
      "--- Example 2 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: did you have fun fishing i hope that we go there another time\n",
      "\n",
      "Word            NLTK       spaCy      Match   \n",
      "------------------------------------------------\n",
      "did             VBD        VBD        âœ“       \n",
      "you             PRP        PRP        âœ“       \n",
      "have            VBP        VB         âœ—       \n",
      "fun             VBN        NN         âœ—       \n",
      "fishing         NN         NN         âœ“       \n",
      "i               NN         PRP        âœ—       \n",
      "hope            VBP        VBP        âœ“       \n",
      "that            IN         IN         âœ“       \n",
      "we              PRP        PRP        âœ“       \n",
      "go              VBP        VBP        âœ“       \n",
      "there           RB         RB         âœ“       \n",
      "another         DT         DT         âœ“       \n",
      "time            NN         NN         âœ“       \n",
      "\n",
      "Agreement: 10/13 (76.9%)\n",
      "Disagreements: 3\n",
      "  â€¢ 'have': NLTK=VBP, spaCy=VB\n",
      "  â€¢ 'fun': NLTK=VBN, spaCy=NN\n",
      "  â€¢ 'i': NLTK=NN, spaCy=PRP\n",
      "\n",
      "--- Example 3 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: are we dad i'm glad momma while you're in there can you get me two crackers two graham crackers with peanut butter\n",
      "\n",
      "Word            NLTK       spaCy      Match   \n",
      "------------------------------------------------\n",
      "are             VBP        VBP        âœ“       \n",
      "we              PRP        PRP        âœ“       \n",
      "dad             VBP        NN         âœ—       \n",
      "i               JJ         PRP        âœ—       \n",
      "am              VBP        VBP        âœ“       \n",
      "glad            JJ         JJ         âœ“       \n",
      "momma           NN         NN         âœ“       \n",
      "while           IN         IN         âœ“       \n",
      "you             PRP        PRP        âœ“       \n",
      "are             VBP        VBP        âœ“       \n",
      "in              IN         IN         âœ“       \n",
      "there           EX         EX         âœ“       \n",
      "can             MD         MD         âœ“       \n",
      "you             PRP        PRP        âœ“       \n",
      "get             VB         VB         âœ“       \n",
      "me              PRP        PRP        âœ“       \n",
      "two             CD         CD         âœ“       \n",
      "crackers        NNS        NNS        âœ“       \n",
      "two             CD         CD         âœ“       \n",
      "graham          JJ         NN         âœ—       \n",
      "crackers        NNS        NNS        âœ“       \n",
      "with            IN         IN         âœ“       \n",
      "peanut          NN         NN         âœ“       \n",
      "butter          NN         NN         âœ“       \n",
      "\n",
      "Agreement: 21/24 (87.5%)\n",
      "Disagreements: 3\n",
      "  â€¢ 'dad': NLTK=VBP, spaCy=NN\n",
      "  â€¢ 'i': NLTK=JJ, spaCy=PRP\n",
      "  â€¢ 'graham': NLTK=JJ, spaCy=NN\n",
      "\n",
      "============================================================\n",
      "MOST COMMON TAG DISAGREEMENTS\n",
      "============================================================\n",
      "\n",
      "Top 10 tag disagreement patterns:\n",
      " 1. NLTK:NN vs spaCy:PRP           (n=661) Examples: one, em, theirs\n",
      " 2. NLTK:NN vs spaCy:NNP           (n=208) Examples: dempsey, graham, lone\n",
      " 3. NLTK:NN vs spaCy:UH            (n=174) Examples: fine, yep, momma\n",
      " 4. NLTK:JJ vs spaCy:PRP           (n=169) Examples: mine, em, ya\n",
      " 5. NLTK:NNS vs spaCy:PRP          (n=144) Examples: em, yours, ours\n",
      " 6. NLTK:VBP vs spaCy:VB           (n=121) Examples: want, make, send\n",
      " 7. NLTK:JJ vs spaCy:NN            (n=119) Examples: terri, everytime, nose\n",
      " 8. NLTK:VB vs spaCy:PRP           (n=111) Examples: myself, em, i\n",
      " 9. NLTK:DT vs spaCy:UH            (n=100) Examples: no\n",
      "10. NLTK:NN vs spaCy:VB            (n= 97) Examples: ask, grow, pudgy\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare NLTK tags vs spaCy tags across ALL utterances\n",
    "if results_spacy is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPREHENSIVE COMPARISON: NLTK vs spaCy POS Tags\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_agreements = 0\n",
    "    total_tokens = 0\n",
    "    per_utterance_agreements = []\n",
    "    \n",
    "    # Calculate agreement across all utterances\n",
    "    for idx in range(len(results_spacy)):\n",
    "        sample_row = results_spacy.iloc[idx]\n",
    "        \n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        spacy_tags = ast.literal_eval(sample_row['tagged_stan_token'])\n",
    "        \n",
    "        if nltk_tags and spacy_tags and len(nltk_tags) == len(spacy_tags):\n",
    "            agreements = sum(1 for (_, t1), (_, t2) in zip(nltk_tags, spacy_tags) if t1 == t2)\n",
    "            total_agreements += agreements\n",
    "            total_tokens += len(nltk_tags)\n",
    "            \n",
    "            # Track per-utterance agreement\n",
    "            utterance_pct = (agreements / len(nltk_tags)) * 100\n",
    "            per_utterance_agreements.append(utterance_pct)\n",
    "    \n",
    "    # Overall statistics\n",
    "    overall_agreement_pct = (total_agreements / total_tokens * 100) if total_tokens > 0 else 0\n",
    "    \n",
    "    print(f\"\\nðŸ“Š OVERALL STATISTICS:\")\n",
    "    print(f\"   Total tokens compared: {total_tokens}\")\n",
    "    print(f\"   Agreements: {total_agreements}\")\n",
    "    print(f\"   Disagreements: {total_tokens - total_agreements}\")\n",
    "    print(f\"   Overall Agreement: {overall_agreement_pct:.1f}%\")\n",
    "    \n",
    "    if per_utterance_agreements:\n",
    "        import numpy as np\n",
    "        print(f\"\\n   Per-utterance agreement:\")\n",
    "        print(f\"      Mean: {np.mean(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Median: {np.median(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Min: {np.min(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Max: {np.max(per_utterance_agreements):.1f}%\")\n",
    "    \n",
    "    # Show detailed examples\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED EXAMPLES (First 3 utterances with >5 words)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    examples_shown = 0\n",
    "    for idx in range(len(results_spacy)):\n",
    "        if examples_shown >= 3:\n",
    "            break\n",
    "            \n",
    "        sample_row = results_spacy.iloc[idx]\n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        spacy_tags = ast.literal_eval(sample_row['tagged_stan_token'])\n",
    "        \n",
    "        if len(nltk_tags) > 5 and len(spacy_tags) > 5:\n",
    "            examples_shown += 1\n",
    "            \n",
    "            print(f\"\\n--- Example {examples_shown} ---\")\n",
    "            print(f\"Source: {sample_row.get('file', 'unknown')}\")\n",
    "            print(f\"Participant: {sample_row.get('participant', 'unknown')}\")\n",
    "            print(f\"Utterance: {sample_row['content']}\\n\")\n",
    "            print(f\"{'Word':<15} {'NLTK':<10} {'spaCy':<10} {'Match':<8}\")\n",
    "            print(\"-\" * 48)\n",
    "            \n",
    "            agreements = 0\n",
    "            disagreements = []\n",
    "            \n",
    "            for (word_n, tag_n), (word_s, tag_s) in zip(nltk_tags, spacy_tags):\n",
    "                match = \"âœ“\" if tag_n == tag_s else \"âœ—\"\n",
    "                print(f\"{word_n:<15} {tag_n:<10} {tag_s:<10} {match:<8}\")\n",
    "                \n",
    "                if tag_n == tag_s:\n",
    "                    agreements += 1\n",
    "                else:\n",
    "                    disagreements.append((word_n, tag_n, tag_s))\n",
    "            \n",
    "            total = len(nltk_tags)\n",
    "            print(f\"\\nAgreement: {agreements}/{total} ({100*agreements/total:.1f}%)\")\n",
    "            \n",
    "            if disagreements:\n",
    "                print(f\"Disagreements: {len(disagreements)}\")\n",
    "                for word, nltk_tag, spacy_tag in disagreements[:3]:  # Show first 3\n",
    "                    print(f\"  â€¢ '{word}': NLTK={nltk_tag}, spaCy={spacy_tag}\")\n",
    "    \n",
    "    # Identify most common disagreements\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MOST COMMON TAG DISAGREEMENTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    disagreement_counts = {}\n",
    "    for idx in range(len(results_spacy)):\n",
    "        sample_row = results_spacy.iloc[idx]\n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        spacy_tags = ast.literal_eval(sample_row['tagged_stan_token'])\n",
    "        \n",
    "        if nltk_tags and spacy_tags:\n",
    "            for (word, t1), (_, t2) in zip(nltk_tags, spacy_tags):\n",
    "                if t1 != t2:\n",
    "                    key = f\"NLTK:{t1} vs spaCy:{t2}\"\n",
    "                    if key not in disagreement_counts:\n",
    "                        disagreement_counts[key] = []\n",
    "                    disagreement_counts[key].append(word)\n",
    "    \n",
    "    # Show top 10 disagreements\n",
    "    if disagreement_counts:\n",
    "        sorted_disagreements = sorted(disagreement_counts.items(), \n",
    "                                     key=lambda x: len(x[1]), \n",
    "                                     reverse=True)\n",
    "        \n",
    "        print(\"\\nTop 10 tag disagreement patterns:\")\n",
    "        for i, (pattern, words) in enumerate(sorted_disagreements[:10], 1):\n",
    "            example_words = ', '.join(list(set(words))[:3])  # Show up to 3 unique examples\n",
    "            print(f\"{i:2}. {pattern:<30} (n={len(words):3}) Examples: {example_words}\")\n",
    "    else:\n",
    "        print(\"\\nâœ“ Perfect agreement! No disagreements found.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2 SUMMARY: spaCy Preprocessing\n",
      "============================================================\n",
      "\n",
      "âœ“ TEST 2 PASSED: spaCy preprocessing works correctly!\n",
      "\n",
      "spaCy tags are being generated and stored properly.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 2 SUMMARY: spaCy Preprocessing\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if results_spacy is not None:\n",
    "    test2_passed = has_spacy_cols and len(results_spacy) > 0\n",
    "    \n",
    "    if test2_passed:\n",
    "        print(\"\\nâœ“ TEST 2 PASSED: spaCy preprocessing works correctly!\")\n",
    "        print(\"\\nspaCy tags are being generated and stored properly.\")\n",
    "    else:\n",
    "        print(\"\\nâœ— TEST 2 FAILED: spaCy preprocessing had issues.\")\n",
    "else:\n",
    "    print(\"\\nâŠ˜ TEST 2 SKIPPED: spaCy not available\")\n",
    "    test2_passed = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 3: Preprocessing with Stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Checking Java installation...\n",
      "----------------------------------------\n",
      "âœ“ Java is installed: java version \"1.8.0_471\"\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Step 1: Check if Java is installed\n",
    "print(\"\\n1. Checking Java installation...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "java_available = False\n",
    "try:\n",
    "    result = subprocess.run(['java', '-version'], \n",
    "                          capture_output=True, \n",
    "                          text=True, \n",
    "                          timeout=5)\n",
    "    \n",
    "    # Check both stderr and stdout for Java version info\n",
    "    output = result.stderr + result.stdout\n",
    "    \n",
    "    # Java typically outputs to stderr, and should contain \"version\"\n",
    "    # Check return code AND output content\n",
    "    if result.returncode == 0 and ('version' in output.lower() or 'openjdk' in output.lower()):\n",
    "        # Extract version line (usually first line)\n",
    "        version_lines = [line for line in output.split('\\n') if line.strip()]\n",
    "        if version_lines:\n",
    "            java_version = version_lines[0]\n",
    "            # Double-check it's not an error message\n",
    "            if 'unable to locate' not in java_version.lower() and 'not found' not in java_version.lower():\n",
    "                print(f\"âœ“ Java is installed: {java_version}\")\n",
    "                java_available = True\n",
    "            else:\n",
    "                print(\"âœ— Java not found\")\n",
    "                print(f\"  Error: {java_version}\")\n",
    "    else:\n",
    "        print(\"âœ— Java not found or not working properly\")\n",
    "        if output.strip():\n",
    "            print(f\"  Output: {output.strip()[:100]}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"âœ— Java command not found\")\n",
    "    print(\"  Java is not installed or not in PATH\")\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"âœ— Java check timed out\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error checking Java: {e}\")\n",
    "\n",
    "if not java_available:\n",
    "    print(\"\\n  Stanford POS Tagger requires Java to run\")\n",
    "    print(\"  Install Java from:\")\n",
    "    print(\"    - macOS: https://www.java.com/en/download/\")\n",
    "    print(\"    - macOS (alternative): brew install openjdk\")\n",
    "    print(\"    - Linux: sudo apt-get install default-jdk\")\n",
    "    print(\"    - Windows: https://www.java.com/en/download/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Checking Stanford POS Tagger files...\n",
      "----------------------------------------\n",
      "âœ— Stanford POS Tagger not found in common locations\n",
      "\n",
      "To use Stanford tagger:\n",
      "  1. Download from: https://nlp.stanford.edu/software/tagger.shtml#Download\n",
      "  2. Extract to a known location\n",
      "  3. Update the paths below\n",
      "\n",
      "Common locations checked:\n",
      "  - /Users/ndd697/stanford-postagger\n",
      "  - /Users/ndd697/Downloads/stanford-postagger-full-2020-11-17\n",
      "  - /usr/local/stanford-postagger\n",
      "  - ./stanford-postagger\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check for Stanford POS Tagger files\n",
    "print(\"\\n2. Checking Stanford POS Tagger files...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "stanford_available = False\n",
    "stanford_pos_path = None\n",
    "stanford_language_path = None\n",
    "\n",
    "if java_available:\n",
    "    # Common locations where users might have Stanford tagger\n",
    "    common_locations = [\n",
    "        os.path.expanduser(\"~/stanford-postagger\"),\n",
    "        os.path.expanduser(\"~/Downloads/stanford-postagger-full-2020-11-17\"),\n",
    "        \"/usr/local/stanford-postagger\",\n",
    "        \"./stanford-postagger\",\n",
    "    ]\n",
    "    \n",
    "    # Check if any common location exists\n",
    "    for location in common_locations:\n",
    "        if os.path.exists(location):\n",
    "            # Check for required files\n",
    "            jar_path = os.path.join(location, \"stanford-postagger.jar\")\n",
    "            model_path = os.path.join(location, \"models/english-left3words-distsim.tagger\")\n",
    "            \n",
    "            if os.path.exists(jar_path) and os.path.exists(model_path):\n",
    "                stanford_pos_path = location\n",
    "                stanford_language_path = \"models/english-left3words-distsim.tagger\"\n",
    "                stanford_available = True\n",
    "                print(f\"âœ“ Found Stanford tagger at: {location}\")\n",
    "                print(f\"  JAR: {jar_path}\")\n",
    "                print(f\"  Model: {model_path}\")\n",
    "                break\n",
    "    \n",
    "    if not stanford_available:\n",
    "        print(\"âœ— Stanford POS Tagger not found in common locations\")\n",
    "        print(\"\\nTo use Stanford tagger:\")\n",
    "        print(\"  1. Download from: https://nlp.stanford.edu/software/tagger.shtml#Download\")\n",
    "        print(\"  2. Extract to a known location\")\n",
    "        print(\"  3. Update the paths below\")\n",
    "        print(\"\\nCommon locations checked:\")\n",
    "        for loc in common_locations:\n",
    "            print(f\"  - {loc}\")\n",
    "else:\n",
    "    print(\"âŠ˜ Skipping (Java not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Path Configuration\n",
      "----------------------------------------\n",
      "\n",
      "âš ï¸  Stanford tagger not auto-detected.\n",
      "If you have Stanford tagger installed, specify paths below:\n",
      "\n",
      "Example paths:\n",
      "  stanford_pos_path = '/Users/yourname/stanford-postagger-full-2020-11-17'\n",
      "  stanford_language_path = 'models/english-left3words-distsim.tagger'\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Manual path configuration (if not auto-detected)\n",
    "print(\"\\n3. Path Configuration\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if java_available and not stanford_available:\n",
    "    print(\"\\nâš ï¸  Stanford tagger not auto-detected.\")\n",
    "    print(\"If you have Stanford tagger installed, specify paths below:\")\n",
    "    print(\"\\nExample paths:\")\n",
    "    print(\"  stanford_pos_path = '/Users/yourname/stanford-postagger-full-2020-11-17'\")\n",
    "    print(\"  stanford_language_path = 'models/english-left3words-distsim.tagger'\")\n",
    "    \n",
    "    # Uncomment and update these lines if you have Stanford tagger installed:\n",
    "    # stanford_pos_path = \"/path/to/your/stanford-postagger\"\n",
    "    # stanford_language_path = \"models/english-left3words-distsim.tagger\"\n",
    "    # stanford_available = True\n",
    "    \n",
    "    if stanford_pos_path and stanford_language_path:\n",
    "        # Validate the paths\n",
    "        jar_path = os.path.join(stanford_pos_path, \"stanford-postagger.jar\")\n",
    "        model_path = os.path.join(stanford_pos_path, stanford_language_path)\n",
    "        \n",
    "        if os.path.exists(jar_path) and os.path.exists(model_path):\n",
    "            stanford_available = True\n",
    "            print(f\"âœ“ Manual configuration successful\")\n",
    "        else:\n",
    "            print(f\"âœ— Invalid paths:\")\n",
    "            if not os.path.exists(jar_path):\n",
    "                print(f\"  JAR not found: {jar_path}\")\n",
    "            if not os.path.exists(model_path):\n",
    "                print(f\"  Model not found: {model_path}\")\n",
    "            stanford_available = False\n",
    "elif stanford_available:\n",
    "    print(f\"âœ“ Using auto-detected paths:\")\n",
    "    print(f\"  Base: {stanford_pos_path}\")\n",
    "    print(f\"  Model: {stanford_language_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stanford-postagger-full-2020-11-17'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford_pos_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Test Results\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ”„ Detected manually configured paths. Validating...\n",
      "  Checking JAR: stanford-postagger-full-2020-11-17/stanford-postagger.jar\n",
      "  Checking Model: stanford-postagger-full-2020-11-17/stanford-postagger-full-2020-11-17/models/english-left3words-distsim.tagger\n",
      "  âœ— Validation failed:\n",
      "    - Model not found: stanford-postagger-full-2020-11-17/stanford-postagger-full-2020-11-17/models/english-left3words-distsim.tagger\n",
      "\n",
      "  ðŸ’¡ Tips:\n",
      "    - stanford_pos_path should point to the Stanford tagger directory\n",
      "    - stanford_language_path can be either:\n",
      "      â€¢ Relative: 'models/english-left3words-distsim.tagger'\n",
      "      â€¢ Absolute: '/full/path/to/models/english-left3words-distsim.tagger'\n",
      "\n",
      "âŠ˜ TEST 3 SKIPPED: Stanford tagger not configured\n",
      "Stanford tagger files not found or paths not specified.\n",
      "\n",
      "ðŸ’¡ To configure manually:\n",
      "   1. Make sure Java is installed\n",
      "   2. Download Stanford POS Tagger from:\n",
      "      https://nlp.stanford.edu/software/tagger.shtml#Download\n",
      "   3. In Step 3 above, set:\n",
      "      stanford_pos_path = '/path/to/stanford-postagger-full-2020-11-17'\n",
      "      stanford_language_path = 'models/english-left3words-distsim.tagger'\n",
      "   4. Re-run this cell (Step 4)\n"
     ]
    }
   ],
   "source": [
    "## MANUALLY DOING THIS\n",
    "stanford_pos_path = '/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/sandbox-prepare/stanford-postagger-full-2020-11-17'\n",
    "stanford_language_path = '/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/sandbox-prepare/stanford-postagger-full-2020-11-17/models/english-left3words-distsim.tagger'\n",
    "\n",
    "# Step 4: Test Stanford tagging (if available)\n",
    "print(\"\\n4. Test Results\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# RE-VALIDATE: Check if paths were manually set after Step 3\n",
    "if not stanford_available and 'stanford_pos_path' in locals() and 'stanford_language_path' in locals():\n",
    "    if stanford_pos_path is not None and stanford_language_path is not None:\n",
    "        print(\"\\nðŸ”„ Detected manually configured paths. Validating...\")\n",
    "        \n",
    "        # Normalize paths\n",
    "        stanford_pos_path = os.path.normpath(os.path.expanduser(stanford_pos_path))\n",
    "        stanford_language_path = os.path.normpath(stanford_language_path)\n",
    "        \n",
    "        # Check if stanford_language_path is absolute or relative\n",
    "        if os.path.isabs(stanford_language_path):\n",
    "            # It's an absolute path, use it directly\n",
    "            model_path = stanford_language_path\n",
    "        else:\n",
    "            # It's relative to stanford_pos_path\n",
    "            model_path = os.path.join(stanford_pos_path, stanford_language_path)\n",
    "        \n",
    "        jar_path = os.path.join(stanford_pos_path, \"stanford-postagger.jar\")\n",
    "        \n",
    "        print(f\"  Checking JAR: {jar_path}\")\n",
    "        print(f\"  Checking Model: {model_path}\")\n",
    "        \n",
    "        if os.path.exists(jar_path) and os.path.exists(model_path):\n",
    "            stanford_available = True\n",
    "            print(f\"  âœ“ Manual configuration validated!\")\n",
    "            print(f\"  âœ“ Found JAR: {os.path.basename(jar_path)}\")\n",
    "            print(f\"  âœ“ Found Model: {os.path.basename(model_path)}\")\n",
    "            \n",
    "            # Update stanford_language_path to be relative if it was given as absolute\n",
    "            if os.path.isabs(stanford_language_path):\n",
    "                # Convert to relative path from stanford_pos_path\n",
    "                try:\n",
    "                    stanford_language_path = os.path.relpath(model_path, stanford_pos_path)\n",
    "                    print(f\"  â„¹ï¸  Converted to relative path: {stanford_language_path}\")\n",
    "                except ValueError:\n",
    "                    # Can't make relative (e.g., different drives on Windows)\n",
    "                    print(f\"  â„¹ï¸  Using absolute model path\")\n",
    "        else:\n",
    "            print(f\"  âœ— Validation failed:\")\n",
    "            if not os.path.exists(jar_path):\n",
    "                print(f\"    - JAR not found: {jar_path}\")\n",
    "            if not os.path.exists(model_path):\n",
    "                print(f\"    - Model not found: {model_path}\")\n",
    "            print(f\"\\n  ðŸ’¡ Tips:\")\n",
    "            print(f\"    - stanford_pos_path should point to the Stanford tagger directory\")\n",
    "            print(f\"    - stanford_language_path can be either:\")\n",
    "            print(f\"      â€¢ Relative: 'models/english-left3words-distsim.tagger'\")\n",
    "            print(f\"      â€¢ Absolute: '/full/path/to/models/english-left3words-distsim.tagger'\")\n",
    "\n",
    "# Now proceed with the test\n",
    "if not java_available:\n",
    "    print(\"\\nâŠ˜ TEST 3 SKIPPED: Java not installed\")\n",
    "    print(\"Stanford tagger requires Java to run.\")\n",
    "    stanford_test_passed = None\n",
    "    \n",
    "elif not stanford_available:\n",
    "    print(\"\\nâŠ˜ TEST 3 SKIPPED: Stanford tagger not configured\")\n",
    "    print(\"Stanford tagger files not found or paths not specified.\")\n",
    "    print(\"\\nðŸ’¡ To configure manually:\")\n",
    "    print(\"   1. Make sure Java is installed\")\n",
    "    print(\"   2. Download Stanford POS Tagger from:\")\n",
    "    print(\"      https://nlp.stanford.edu/software/tagger.shtml#Download\")\n",
    "    print(\"   3. In Step 3 above, set:\")\n",
    "    print(\"      stanford_pos_path = '/path/to/stanford-postagger-full-2020-11-17'\")\n",
    "    print(\"      stanford_language_path = 'models/english-left3words-distsim.tagger'\")\n",
    "    print(\"   4. Re-run this cell (Step 4)\")\n",
    "    stanford_test_passed = None\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâœ“ All prerequisites met. Running Stanford tagger test...\")\n",
    "    print(f\"\\nThis may take several minutes (Stanford tagger is ~100x slower than spaCy)\")\n",
    "    print(f\"Processing {len([f for f in os.listdir(CHILDES_DATA_DIR) if f.endswith('.txt')])} files...\")\n",
    "    \n",
    "    # Create output directory for Stanford test\n",
    "    OUTPUT_DIR_STANFORD = './test_output_stanford'\n",
    "    os.makedirs(OUTPUT_DIR_STANFORD, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results_stanford = prepare_transcripts(\n",
    "            input_files=CHILDES_DATA_DIR,\n",
    "            output_file_directory=OUTPUT_DIR_STANFORD,\n",
    "            run_spell_check=False,\n",
    "            minwords=2,\n",
    "            add_stanford_tags=True,\n",
    "            stanford_tagger_type='stanford',  # Use Stanford\n",
    "            stanford_pos_path=stanford_pos_path,\n",
    "            stanford_language_path=stanford_language_path,\n",
    "            stanford_batch_size=50,  # Process in batches for better performance\n",
    "            input_as_directory=True\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\nâœ“ Stanford preprocessing complete!\")\n",
    "        print(f\"  Time taken: {processing_time:.1f} seconds ({processing_time/60:.1f} minutes)\")\n",
    "        print(f\"  Total utterances processed: {len(results_stanford)}\")\n",
    "        \n",
    "        # Check if Stanford tags were actually created\n",
    "        sample_stanford_tags = ast.literal_eval(results_stanford['tagged_stan_token'].iloc[0])\n",
    "        if sample_stanford_tags:\n",
    "            print(f\"  âœ“ Stanford tags successfully generated\")\n",
    "            stanford_test_passed = True\n",
    "        else:\n",
    "            print(f\"  âœ— Stanford tags are empty\")\n",
    "            stanford_test_passed = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— Stanford preprocessing failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        stanford_test_passed = False\n",
    "        results_stanford = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 3: Integration with Alignment Analysis\n",
    "\n",
    "Test that preprocessed files work correctly with the alignment analysis scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Integration with Alignment Analysis\n",
      "============================================================\n",
      "\n",
      "âœ“ Successfully imported LinguisticAlignment\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 3: Integration with Alignment Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Import alignment analyzer\n",
    "from align_test.alignment import LinguisticAlignment\n",
    "\n",
    "print(\"\\nâœ“ Successfully imported LinguisticAlignment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing alignment analyzer...\n",
      "âœ“ Analyzer initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize alignment analyzer\n",
    "print(\"Initializing alignment analyzer...\")\n",
    "\n",
    "analyzer = LinguisticAlignment(\n",
    "    alignment_type=\"lexsyn\",\n",
    "    cache_dir=os.path.join(OUTPUT_DIR_ALIGNMENT, \"cache\")\n",
    ")\n",
    "\n",
    "print(\"âœ“ Analyzer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running alignment analysis...\n",
      "Input folder: ./test_output_basic\n",
      "Output folder: ./test_alignment_results\n",
      "ANALYZE_FOLDER: Processing data from folder: ./test_output_basic with lag=1\n",
      "Found 22 files to process with lag 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing time197-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:00<00:00, 5002.62it/s]\n",
      "Processing time202-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [00:00<00:00, 5438.09it/s]\n",
      "Processing time191-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:00<00:00, 6079.68it/s]\n",
      "Processing time209-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:00<00:00, 6470.45it/s]\n",
      "Processing time210-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 6922.21it/s]\n",
      "Processing time204-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143/143 [00:00<00:00, 6600.48it/s]\n",
      "Processing time192-cond1-bs.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:00<00:00, 6590.02it/s]\n",
      "Processing time196-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<00:00, 6578.36it/s]\n",
      "Processing time203-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 6541.68it/s]\n",
      "Processing time208-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 6091.53it/s]\n",
      "Processing time205-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:00<00:00, 6452.40it/s]\n",
      "Processing time195-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 6603.12it/s]\n",
      "Processing time198-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 6640.81it/s]\n",
      "Processing time200-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<00:00, 6065.74it/s]\n",
      "Processing time193-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:00<00:00, 6726.18it/s]\n",
      "Processing time206-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [00:00<00:00, 6254.38it/s]\n",
      "Processing time194-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:00<00:00, 6521.44it/s]\n",
      "Processing time199-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:00<00:00, 6286.15it/s]\n",
      "Processing align_concatenated_dataframe.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1832/1832 [00:00<00:00, 6582.59it/s]\n",
      "Processing time201-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 6481.81it/s]\n",
      "Processing time192-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:00<00:00, 6571.84it/s]\n",
      "Processing time207-cond1.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:00<00:00, 6546.07it/s]\n",
      "Processing files with lexsyn: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 21.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 22 out of 22 files\n",
      "Results saved to ./test_alignment_results/lexsyn/lexsyn_alignment_ngram2_lag1_noDups_noStan.csv\n",
      "\n",
      "âœ“ Alignment analysis complete!\n",
      "Utterance pairs analyzed: 3731\n"
     ]
    }
   ],
   "source": [
    "# Run alignment analysis on preprocessed data\n",
    "print(\"\\nRunning alignment analysis...\")\n",
    "print(f\"Input folder: {OUTPUT_DIR_BASIC}\")\n",
    "print(f\"Output folder: {OUTPUT_DIR_ALIGNMENT}\")\n",
    "\n",
    "alignment_results = analyzer.analyze_folder(\n",
    "    folder_path=OUTPUT_DIR_BASIC,\n",
    "    output_directory=OUTPUT_DIR_ALIGNMENT,\n",
    "    lag=1,\n",
    "    max_ngram=2,\n",
    "    ignore_duplicates=True,\n",
    "    add_stanford_tags=False  # Using NLTK-only preprocessed data\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Alignment analysis complete!\")\n",
    "print(f\"Utterance pairs analyzed: {len(alignment_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment Results:\n",
      "Shape: (3731, 24)\n",
      "\n",
      "Columns: ['time', 'source_file', 'participant', 'content', 'token', 'lemma', 'tagged_token', 'tagged_lemma', 'lag', 'utter_order', 'content1', 'content2', 'utterance_length1', 'utterance_length2', 'lexical_tok1_cosine', 'lexical_lem1_cosine', 'pos_tok1_cosine', 'pos_lem1_cosine', 'lexical_tok2_cosine', 'lexical_lem2_cosine', 'pos_tok2_cosine', 'pos_lem2_cosine', 'lexical_master_cosine', 'syntactic_master_cosine']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>source_file</th>\n",
       "      <th>participant</th>\n",
       "      <th>content</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tagged_token</th>\n",
       "      <th>tagged_lemma</th>\n",
       "      <th>lag</th>\n",
       "      <th>utter_order</th>\n",
       "      <th>...</th>\n",
       "      <th>lexical_tok1_cosine</th>\n",
       "      <th>lexical_lem1_cosine</th>\n",
       "      <th>pos_tok1_cosine</th>\n",
       "      <th>pos_lem1_cosine</th>\n",
       "      <th>lexical_tok2_cosine</th>\n",
       "      <th>lexical_lem2_cosine</th>\n",
       "      <th>pos_tok2_cosine</th>\n",
       "      <th>pos_lem2_cosine</th>\n",
       "      <th>lexical_master_cosine</th>\n",
       "      <th>syntactic_master_cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>cgv</td>\n",
       "      <td>that was fun</td>\n",
       "      <td>[that, was, fun]</td>\n",
       "      <td>[that, be, fun]</td>\n",
       "      <td>[(that, DT), (was, VBD), (fun, NN)]</td>\n",
       "      <td>[(that, DT), (be, VB), (fun, NN)]</td>\n",
       "      <td>1</td>\n",
       "      <td>cgv kid</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.696311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>kid</td>\n",
       "      <td>dad you should have climbed the cliffs with us</td>\n",
       "      <td>[dad, you, should, have, climbed, the, cliffs,...</td>\n",
       "      <td>[dad, you, should, have, climb, the, cliff, wi...</td>\n",
       "      <td>[(dad, NN), (you, PRP), (should, MD), (have, V...</td>\n",
       "      <td>[(dad, NN), (you, PRP), (should, MD), (have, V...</td>\n",
       "      <td>1</td>\n",
       "      <td>kid cgv</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369274</td>\n",
       "      <td>0.738549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>cgv</td>\n",
       "      <td>next time i will</td>\n",
       "      <td>[next, time, i, will]</td>\n",
       "      <td>[next, time, i, will]</td>\n",
       "      <td>[(next, JJ), (time, NN), (i, NN), (will, MD)]</td>\n",
       "      <td>[(next, JJ), (time, NN), (i, NN), (will, MD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>cgv kid</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138675</td>\n",
       "      <td>0.077152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>kid</td>\n",
       "      <td>did you have fun fishing i hope that we go the...</td>\n",
       "      <td>[did, you, have, fun, fishing, i, hope, that, ...</td>\n",
       "      <td>[do, you, have, fun, fishing, i, hope, that, w...</td>\n",
       "      <td>[(did, VBD), (you, PRP), (have, VBP), (fun, VB...</td>\n",
       "      <td>[(do, VBP), (you, PRP), (have, VB), (fun, VBN)...</td>\n",
       "      <td>1</td>\n",
       "      <td>kid cgv</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>cgv</td>\n",
       "      <td>i bet we will</td>\n",
       "      <td>[i, bet, we, will]</td>\n",
       "      <td>[i, bet, we, will]</td>\n",
       "      <td>[(i, JJ), (bet, NN), (we, PRP), (will, MD)]</td>\n",
       "      <td>[(i, JJ), (bet, NN), (we, PRP), (will, MD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>cgv kid</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176777</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.371391</td>\n",
       "      <td>0.533745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.09245</td>\n",
       "      <td>0.085861</td>\n",
       "      <td>0.101781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        source_file participant  \\\n",
       "0     1  time197-cond1.txt         cgv   \n",
       "1     2  time197-cond1.txt         kid   \n",
       "2     3  time197-cond1.txt         cgv   \n",
       "3     4  time197-cond1.txt         kid   \n",
       "4     5  time197-cond1.txt         cgv   \n",
       "\n",
       "                                             content  \\\n",
       "0                                       that was fun   \n",
       "1     dad you should have climbed the cliffs with us   \n",
       "2                                   next time i will   \n",
       "3  did you have fun fishing i hope that we go the...   \n",
       "4                                      i bet we will   \n",
       "\n",
       "                                               token  \\\n",
       "0                                   [that, was, fun]   \n",
       "1  [dad, you, should, have, climbed, the, cliffs,...   \n",
       "2                              [next, time, i, will]   \n",
       "3  [did, you, have, fun, fishing, i, hope, that, ...   \n",
       "4                                 [i, bet, we, will]   \n",
       "\n",
       "                                               lemma  \\\n",
       "0                                    [that, be, fun]   \n",
       "1  [dad, you, should, have, climb, the, cliff, wi...   \n",
       "2                              [next, time, i, will]   \n",
       "3  [do, you, have, fun, fishing, i, hope, that, w...   \n",
       "4                                 [i, bet, we, will]   \n",
       "\n",
       "                                        tagged_token  \\\n",
       "0                [(that, DT), (was, VBD), (fun, NN)]   \n",
       "1  [(dad, NN), (you, PRP), (should, MD), (have, V...   \n",
       "2      [(next, JJ), (time, NN), (i, NN), (will, MD)]   \n",
       "3  [(did, VBD), (you, PRP), (have, VBP), (fun, VB...   \n",
       "4        [(i, JJ), (bet, NN), (we, PRP), (will, MD)]   \n",
       "\n",
       "                                        tagged_lemma  lag utter_order  ...  \\\n",
       "0                  [(that, DT), (be, VB), (fun, NN)]    1     cgv kid  ...   \n",
       "1  [(dad, NN), (you, PRP), (should, MD), (have, V...    1     kid cgv  ...   \n",
       "2      [(next, JJ), (time, NN), (i, NN), (will, MD)]    1     cgv kid  ...   \n",
       "3  [(do, VBP), (you, PRP), (have, VB), (fun, VBN)...    1     kid cgv  ...   \n",
       "4        [(i, JJ), (bet, NN), (we, PRP), (will, MD)]    1     cgv kid  ...   \n",
       "\n",
       "  lexical_tok1_cosine lexical_lem1_cosine  pos_tok1_cosine  pos_lem1_cosine  \\\n",
       "0            0.000000            0.000000         0.522233         0.696311   \n",
       "1            0.000000            0.000000         0.369274         0.738549   \n",
       "2            0.277350            0.277350         0.000000         0.000000   \n",
       "3            0.277350            0.277350         0.353553         0.258199   \n",
       "4            0.176777            0.166667         0.371391         0.533745   \n",
       "\n",
       "   lexical_tok2_cosine  lexical_lem2_cosine  pos_tok2_cosine  pos_lem2_cosine  \\\n",
       "0                  0.0                  0.0         0.000000          0.00000   \n",
       "1                  0.0                  0.0         0.000000          0.00000   \n",
       "2                  0.0                  0.0         0.154303          0.00000   \n",
       "3                  0.0                  0.0         0.000000          0.00000   \n",
       "4                  0.0                  0.0         0.111111          0.09245   \n",
       "\n",
       "   lexical_master_cosine  syntactic_master_cosine  \n",
       "0               0.000000                 0.000000  \n",
       "1               0.000000                 0.000000  \n",
       "2               0.138675                 0.077152  \n",
       "3               0.138675                 0.000000  \n",
       "4               0.085861                 0.101781  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine alignment results\n",
    "print(\"Alignment Results:\")\n",
    "print(f\"Shape: {alignment_results.shape}\")\n",
    "print(f\"\\nColumns: {alignment_results.columns.tolist()}\")\n",
    "\n",
    "alignment_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Alignment Metrics:\n",
      "----------------------------------------\n",
      "âœ“ lexical_tok1_cosine\n",
      "âœ“ lexical_lem1_cosine\n",
      "âœ“ pos_tok1_cosine\n",
      "âœ“ pos_lem1_cosine\n",
      "âœ“ lexical_master_cosine\n",
      "âœ“ syntactic_master_cosine\n",
      "\n",
      "Found 6/6 expected metrics\n"
     ]
    }
   ],
   "source": [
    "# Check for expected alignment metrics\n",
    "expected_metrics = [\n",
    "    'lexical_tok1_cosine',\n",
    "    'lexical_lem1_cosine', \n",
    "    'pos_tok1_cosine',\n",
    "    'pos_lem1_cosine',\n",
    "    'lexical_master_cosine',\n",
    "    'syntactic_master_cosine'\n",
    "]\n",
    "\n",
    "print(\"Expected Alignment Metrics:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "found_metrics = []\n",
    "for metric in expected_metrics:\n",
    "    present = metric in alignment_results.columns\n",
    "    status = \"âœ“\" if present else \"âœ—\"\n",
    "    print(f\"{status} {metric}\")\n",
    "    if present:\n",
    "        found_metrics.append(metric)\n",
    "\n",
    "print(f\"\\nFound {len(found_metrics)}/{len(expected_metrics)} expected metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Alignment Scores:\n",
      "============================================================\n",
      "Source: time197-cond1.txt\n",
      "Participant: cgv\n",
      "Content: that was fun\n",
      "\n",
      "Alignment Scores:\n",
      "  lexical_tok1_cosine: 0.0000\n",
      "  lexical_lem1_cosine: 0.0000\n",
      "  pos_tok1_cosine: 0.5222\n",
      "  pos_lem1_cosine: 0.6963\n",
      "  lexical_master_cosine: 0.0000\n",
      "  syntactic_master_cosine: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Show sample alignment scores\n",
    "if found_metrics:\n",
    "    print(\"\\nSample Alignment Scores:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sample = alignment_results.iloc[0]\n",
    "    \n",
    "    print(f\"Source: {sample['source_file']}\")\n",
    "    print(f\"Participant: {sample['participant']}\")\n",
    "    print(f\"Content: {sample['content']}\")\n",
    "    print(f\"\\nAlignment Scores:\")\n",
    "    \n",
    "    for metric in found_metrics:\n",
    "        if metric in sample:\n",
    "            value = sample[metric]\n",
    "            print(f\"  {metric}: {value:.4f}\" if pd.notna(value) else f\"  {metric}: NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Visualize alignment scores distribution\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mlexical_master_cosine\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m alignment_results.columns:\n\u001b[32m      5\u001b[39m     fig, axes = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Visualize alignment scores distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'lexical_master_cosine' in alignment_results.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Lexical alignment distribution\n",
    "    alignment_results['lexical_master_cosine'].hist(ax=axes[0], bins=20)\n",
    "    axes[0].set_title('Lexical Alignment Distribution')\n",
    "    axes[0].set_xlabel('Lexical Master Cosine')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Syntactic alignment distribution\n",
    "    if 'syntactic_master_cosine' in alignment_results.columns:\n",
    "        alignment_results['syntactic_master_cosine'].hist(ax=axes[1], bins=20)\n",
    "        axes[1].set_title('Syntactic Alignment Distribution')\n",
    "        axes[1].set_xlabel('Syntactic Master Cosine')\n",
    "        axes[1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nAlignment Score Statistics:\")\n",
    "    print(\"=\"*60)\n",
    "    print(alignment_results[['lexical_master_cosine', 'syntactic_master_cosine']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 3 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 3 SUMMARY: Alignment Integration\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test3_passed = len(alignment_results) > 0 and len(found_metrics) >= 4\n",
    "\n",
    "if test3_passed:\n",
    "    print(\"\\nâœ“ TEST 3 PASSED: Integration with alignment analysis works!\")\n",
    "    print(\"\\nPreprocessed files are fully compatible with alignment analysis.\")\n",
    "    print(f\"Successfully analyzed {len(alignment_results)} utterance pairs.\")\n",
    "else:\n",
    "    print(\"\\nâœ— TEST 3 FAILED: Integration issues detected.\")\n",
    "    print(\"Please review the test results above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 4: Check Output Files\n",
    "\n",
    "Verify that the saved output files on disk are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 4: Output Files on Disk\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check basic output directory\n",
    "print(f\"\\nBasic output directory: {OUTPUT_DIR_BASIC}\")\n",
    "basic_files = [f for f in os.listdir(OUTPUT_DIR_BASIC) if f.endswith('.txt')]\n",
    "print(f\"Files created: {len(basic_files)}\")\n",
    "for f in basic_files:\n",
    "    size_kb = os.path.getsize(os.path.join(OUTPUT_DIR_BASIC, f)) / 1024\n",
    "    print(f\"  - {f} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify a saved file\n",
    "if basic_files:\n",
    "    test_file = os.path.join(OUTPUT_DIR_BASIC, basic_files[0])\n",
    "    print(f\"\\nVerifying saved file: {basic_files[0]}\")\n",
    "    \n",
    "    # Load from disk\n",
    "    saved_df = pd.read_csv(test_file, sep='\\t', encoding='utf-8')\n",
    "    print(f\"âœ“ Loaded {len(saved_df)} rows from disk\")\n",
    "    \n",
    "    # Quick format check\n",
    "    token_str = saved_df['token'].iloc[0]\n",
    "    print(f\"\\nToken column type: {type(token_str)}\")\n",
    "    print(f\"Token value: {token_str[:80]}...\")\n",
    "    \n",
    "    # Parse check\n",
    "    try:\n",
    "        token_list = ast.literal_eval(token_str)\n",
    "        print(f\"âœ“ Successfully parsed to: {type(token_list).__name__}\")\n",
    "        print(f\"  Contents: {token_list}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Parse failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Summary\n",
    "\n",
    "Overall test results and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect results\n",
    "test_results = {\n",
    "    \"TEST 1: Basic Preprocessing (NLTK)\": test1_passed,\n",
    "    \"TEST 2: spaCy Integration\": test2_passed if test2_passed is not None else \"SKIPPED\",\n",
    "    \"TEST 3: Alignment Integration\": test3_passed\n",
    "}\n",
    "\n",
    "# Print results\n",
    "for test_name, result in test_results.items():\n",
    "    if result == \"SKIPPED\":\n",
    "        print(f\"âŠ˜ {test_name}: SKIPPED\")\n",
    "    elif result:\n",
    "        print(f\"âœ“ {test_name}: PASSED\")\n",
    "    else:\n",
    "        print(f\"âœ— {test_name}: FAILED\")\n",
    "\n",
    "# Overall assessment\n",
    "passed_tests = [r for r in test_results.values() if r is True]\n",
    "failed_tests = [r for r in test_results.values() if r is False]\n",
    "\n",
    "print(f\"\\nResults: {len(passed_tests)} passed, {len(failed_tests)} failed\")\n",
    "\n",
    "if len(failed_tests) == 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸŽ‰ ALL TESTS PASSED!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nThe refactored prepare_transcripts.py is working correctly!\")\n",
    "    print(\"\\nYou can now:\")\n",
    "    print(\"  1. Use prepare_transcripts with your own data\")\n",
    "    print(\"  2. Run alignment analysis on preprocessed output\")\n",
    "    print(\"  3. Generate baseline comparisons with surrogates\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âš ï¸  SOME TESTS FAILED\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nPlease review the failed tests above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Quick Preprocessing Example\n",
    "\n",
    "Once tests pass, here's how to preprocess your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Preprocess with spaCy (recommended)\n",
    "# Uncomment and modify paths for your own data\n",
    "\n",
    "# from align_test.prepare_transcripts_refactored import prepare_transcripts\n",
    "\n",
    "# my_results = prepare_transcripts(\n",
    "#     input_files=\"/path/to/my/raw/transcripts\",\n",
    "#     output_file_directory=\"/path/to/my/preprocessed/output\",\n",
    "#     run_spell_check=True,\n",
    "#     minwords=2,\n",
    "#     add_stanford_tags=True,\n",
    "#     stanford_tagger_type='spacy',  # Recommended: fast and accurate\n",
    "#     save_concatenated_dataframe=True\n",
    "# )\n",
    "\n",
    "# print(f\"Preprocessed {len(my_results)} utterances!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Full Pipeline Example\n",
    "\n",
    "Complete workflow from raw data to alignment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Complete pipeline\n",
    "# Uncomment to run on your own data\n",
    "\n",
    "# # Step 1: Preprocess\n",
    "# preprocessed = prepare_transcripts(\n",
    "#     input_files=\"./my_raw_data\",\n",
    "#     output_file_directory=\"./my_preprocessed\",\n",
    "#     add_stanford_tags=True,\n",
    "#     stanford_tagger_type='spacy'\n",
    "# )\n",
    "\n",
    "# # Step 2: Analyze alignment\n",
    "# from align_test.alignment import LinguisticAlignment\n",
    "\n",
    "# analyzer = LinguisticAlignment(alignment_types=[\"lexsyn\", \"fasttext\"])\n",
    "# results = analyzer.analyze_folder(\n",
    "#     folder_path=\"./my_preprocessed\",\n",
    "#     output_directory=\"./my_results\",\n",
    "#     lag=1,\n",
    "#     max_ngram=2,\n",
    "#     add_stanford_tags=True  # Use spaCy tags from preprocessing\n",
    "# )\n",
    "\n",
    "# # Step 3: Generate baseline\n",
    "# baseline = analyzer.analyze_baseline(\n",
    "#     input_files=\"./my_preprocessed\",\n",
    "#     output_directory=\"./my_results\",\n",
    "#     lag=1,\n",
    "#     max_ngram=2,\n",
    "#     add_stanford_tags=True,\n",
    "#     id_separator=\"-\",\n",
    "#     condition_label=\"cond\",\n",
    "#     dyad_label=\"dyad\"\n",
    "# )\n",
    "\n",
    "# print(\"Complete pipeline finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
