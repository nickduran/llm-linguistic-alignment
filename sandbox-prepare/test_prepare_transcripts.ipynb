{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Suite for Refactored `prepare_transcripts.py`\n",
    "\n",
    "This notebook tests the refactored preprocessing module with CHILDES sample data and verifies compatibility with alignment analysis scripts.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you've:\n",
    "1. Installed the package in editable mode: `pip install -e .`\n",
    "2. Installed spaCy: `pip install spacy` [NOTE: is this necessary?]\n",
    "3. Downloaded spaCy model: `python -m spacy download en_core_web_sm` [NOTE: is this necessary?]\n",
    "\n",
    "## Data Location\n",
    "\n",
    "Test files: `/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/src/align_test/data/CHILDES/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Import Libraries and Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Import the refactored preprocessing module\n",
    "from align_test.prepare_transcripts import prepare_transcripts\n",
    "\n",
    "print(\"✓ Imports successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created directory: ./test_output_basic\n",
      "✓ Created directory: ./test_output_spacy\n",
      "✓ Created directory: ./test_alignment_results\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION: Set your data directories\n",
    "# ============================================================\n",
    "\n",
    "# Input: CHILDES data directory\n",
    "CHILDES_DATA_DIR = '/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/src/align_test/data/CHILDES/'\n",
    "\n",
    "# Output: Test output directories\n",
    "OUTPUT_DIR_BASIC = './test_output_basic'\n",
    "OUTPUT_DIR_SPACY = './test_output_spacy'\n",
    "OUTPUT_DIR_ALIGNMENT = './test_alignment_results'\n",
    "\n",
    "# Create output directories\n",
    "for dir_path in [OUTPUT_DIR_BASIC, OUTPUT_DIR_SPACY, OUTPUT_DIR_ALIGNMENT]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"✓ Created directory: {dir_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify Input Data\n",
    "\n",
    "Check that the CHILDES directory exists and contains our test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHILDES Directory: /Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/src/align_test/data/CHILDES/\n",
      "Exists: True\n",
      "\n",
      "✓ Found 20 .txt files:\n",
      "  - time197-cond1.txt (4.4 KB)\n",
      "  - time202-cond1.txt (6.2 KB)\n",
      "  - time191-cond1.txt (5.5 KB)\n",
      "  - time209-cond1.txt (6.4 KB)\n",
      "  - time210-cond1.txt (5.5 KB)\n",
      "  - time204-cond1.txt (8.8 KB)\n",
      "  - time196-cond1.txt (4.3 KB)\n",
      "  - time203-cond1.txt (5.3 KB)\n",
      "  - time208-cond1.txt (6.5 KB)\n",
      "  - time205-cond1.txt (7.5 KB)\n",
      "  - time195-cond1.txt (5.6 KB)\n",
      "  - time198-cond1.txt (5.3 KB)\n",
      "  - time200-cond1.txt (5.5 KB)\n",
      "  - time193-cond1.txt (5.7 KB)\n",
      "  - time206-cond1.txt (6.2 KB)\n",
      "  - time194-cond1.txt (5.3 KB)\n",
      "  - time199-cond1.txt (5.9 KB)\n",
      "  - time201-cond1.txt (5.6 KB)\n",
      "  - time192-cond1.txt (4.1 KB)\n",
      "  - time207-cond1.txt (6.5 KB)\n"
     ]
    }
   ],
   "source": [
    "# Check if CHILDES directory exists\n",
    "print(f\"CHILDES Directory: {CHILDES_DATA_DIR}\")\n",
    "print(f\"Exists: {os.path.exists(CHILDES_DATA_DIR)}\")\n",
    "\n",
    "if not os.path.exists(CHILDES_DATA_DIR):\n",
    "    print(\"\\n✗ Directory not found! Please update CHILDES_DATA_DIR above.\")\n",
    "else:\n",
    "    # List files in directory\n",
    "    files = [f for f in os.listdir(CHILDES_DATA_DIR) if f.endswith('.txt')]\n",
    "    print(f\"\\n✓ Found {len(files)} .txt files:\")\n",
    "    for f in files:\n",
    "        file_path = os.path.join(CHILDES_DATA_DIR, f)\n",
    "        size_kb = os.path.getsize(file_path) / 1024\n",
    "        print(f\"  - {f} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inspect Raw Input Files\n",
    "\n",
    "Let's look at the structure of the raw input files before preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: time200-cond1.txt\n",
      "\n",
      "Columns: ['participant', 'content']\n",
      "Rows: 134\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cgv</td>\n",
       "      <td>well hurry Abe it's time to eat are you ready.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kid</td>\n",
       "      <td>is it time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cgv</td>\n",
       "      <td>yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kid</td>\n",
       "      <td>I'm almost done okay Mom now you can come over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cgv</td>\n",
       "      <td>okay.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant                                            content\n",
       "0         cgv     well hurry Abe it's time to eat are you ready.\n",
       "1         kid                                        is it time.\n",
       "2         cgv                                              yeah.\n",
       "3         kid  I'm almost done okay Mom now you can come over...\n",
       "4         cgv                                              okay."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and display a sample input file\n",
    "sample_file = os.path.join(CHILDES_DATA_DIR, 'time200-cond1.txt')\n",
    "\n",
    "print(f\"Reading: {os.path.basename(sample_file)}\\n\")\n",
    "\n",
    "raw_df = pd.read_csv(sample_file, sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(f\"Columns: {raw_df.columns.tolist()}\")\n",
    "print(f\"Rows: {len(raw_df)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample utterances:\n",
      "\n",
      "cgv: well hurry Abe it's time to eat are you ready.\n",
      "kid: is it time.\n",
      "cgv: yeah.\n",
      "kid: I'm almost done okay Mom now you can come over here and look.\n",
      "cgv: okay.\n"
     ]
    }
   ],
   "source": [
    "# Show some sample content\n",
    "print(\"Sample utterances:\\n\")\n",
    "for i in range(min(5, len(raw_df))):\n",
    "    print(f\"{raw_df['participant'].iloc[i]}: {raw_df['content'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 1: Basic Preprocessing (NLTK Only)\n",
    "\n",
    "Test preprocessing with default NLTK POS tagger (fastest option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 1: Basic Preprocessing (NLTK only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run preprocessing with minimal options\n",
    "results_basic = prepare_transcripts(\n",
    "    input_files=CHILDES_DATA_DIR,\n",
    "    output_file_directory=OUTPUT_DIR_BASIC,\n",
    "    run_spell_check=False,  # Disable for faster testing\n",
    "    minwords=2,\n",
    "    add_additional_tags=False,  # NLTK only\n",
    "    input_as_directory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Preprocessing complete!\")\n",
    "print(f\"Total utterances processed: {len(results_basic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output columns:\n",
      "  - participant\n",
      "  - content\n",
      "  - token\n",
      "  - lemma\n",
      "  - tagged_token\n",
      "  - tagged_lemma\n",
      "  - file\n",
      "\n",
      "DataFrame shape: (1832, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>content</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tagged_token</th>\n",
       "      <th>tagged_lemma</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cgv</td>\n",
       "      <td>that was fun</td>\n",
       "      <td>['that', 'was', 'fun']</td>\n",
       "      <td>['that', 'be', 'fun']</td>\n",
       "      <td>[('that', 'DT'), ('was', 'VBD'), ('fun', 'NN')]</td>\n",
       "      <td>[('that', 'DT'), ('be', 'VB'), ('fun', 'NN')]</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kid</td>\n",
       "      <td>dad you should have climbed the cliffs with us</td>\n",
       "      <td>['dad', 'you', 'should', 'have', 'climbed', 't...</td>\n",
       "      <td>['dad', 'you', 'should', 'have', 'climb', 'the...</td>\n",
       "      <td>[('dad', 'NN'), ('you', 'PRP'), ('should', 'MD...</td>\n",
       "      <td>[('dad', 'NN'), ('you', 'PRP'), ('should', 'MD...</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cgv</td>\n",
       "      <td>next time i will</td>\n",
       "      <td>['next', 'time', 'i', 'will']</td>\n",
       "      <td>['next', 'time', 'i', 'will']</td>\n",
       "      <td>[('next', 'JJ'), ('time', 'NN'), ('i', 'NN'), ...</td>\n",
       "      <td>[('next', 'JJ'), ('time', 'NN'), ('i', 'NN'), ...</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant                                         content  \\\n",
       "0         cgv                                    that was fun   \n",
       "1         kid  dad you should have climbed the cliffs with us   \n",
       "2         cgv                                next time i will   \n",
       "\n",
       "                                               token  \\\n",
       "0                             ['that', 'was', 'fun']   \n",
       "1  ['dad', 'you', 'should', 'have', 'climbed', 't...   \n",
       "2                      ['next', 'time', 'i', 'will']   \n",
       "\n",
       "                                               lemma  \\\n",
       "0                              ['that', 'be', 'fun']   \n",
       "1  ['dad', 'you', 'should', 'have', 'climb', 'the...   \n",
       "2                      ['next', 'time', 'i', 'will']   \n",
       "\n",
       "                                        tagged_token  \\\n",
       "0    [('that', 'DT'), ('was', 'VBD'), ('fun', 'NN')]   \n",
       "1  [('dad', 'NN'), ('you', 'PRP'), ('should', 'MD...   \n",
       "2  [('next', 'JJ'), ('time', 'NN'), ('i', 'NN'), ...   \n",
       "\n",
       "                                        tagged_lemma               file  \n",
       "0      [('that', 'DT'), ('be', 'VB'), ('fun', 'NN')]  time197-cond1.txt  \n",
       "1  [('dad', 'NN'), ('you', 'PRP'), ('should', 'MD...  time197-cond1.txt  \n",
       "2  [('next', 'JJ'), ('time', 'NN'), ('i', 'NN'), ...  time197-cond1.txt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the output\n",
    "print(\"Output columns:\")\n",
    "for col in results_basic.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nDataFrame shape: {results_basic.shape}\")\n",
    "results_basic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed utterance:\n",
      "\n",
      "Participant: cgv\n",
      "Content: that was fun\n",
      "\n",
      "Token (string): ['that', 'was', 'fun']...\n",
      "Type: <class 'str'>\n",
      "\n",
      "Token (parsed): ['that', 'was', 'fun']\n",
      "Type after parsing: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Examine a single row in detail\n",
    "print(\"Sample processed utterance:\\n\")\n",
    "sample_row = results_basic.iloc[0]\n",
    "\n",
    "print(f\"Participant: {sample_row['participant']}\")\n",
    "print(f\"Content: {sample_row['content']}\")\n",
    "print(f\"\\nToken (string): {sample_row['token'][:100]}...\")\n",
    "print(f\"Type: {type(sample_row['token'])}\")\n",
    "\n",
    "# Parse and display\n",
    "tokens = ast.literal_eval(sample_row['token'])\n",
    "print(f\"\\nToken (parsed): {tokens}\")\n",
    "print(f\"Type after parsing: {type(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Output Format\n",
    "\n",
    "Check that the output format is compatible with alignment analysis scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files created: ['time197-cond1.txt', 'time202-cond1.txt', 'time191-cond1.txt', 'time209-cond1.txt', 'time210-cond1.txt', 'time204-cond1.txt', 'time192-cond1-bs.txt', 'time196-cond1.txt', 'time203-cond1.txt', 'time208-cond1.txt', 'time205-cond1.txt', 'time195-cond1.txt', 'time198-cond1.txt', 'time200-cond1.txt', 'time193-cond1.txt', 'time206-cond1.txt', 'time194-cond1.txt', 'time199-cond1.txt', 'time201-cond1.txt', 'time192-cond1.txt', 'time207-cond1.txt']\n",
      "\n",
      "Loading: time197-cond1.txt\n",
      "Rows loaded: 76\n",
      "Columns: ['participant', 'content', 'token', 'lemma', 'tagged_token', 'tagged_lemma', 'file']\n"
     ]
    }
   ],
   "source": [
    "# Load one of the saved output files\n",
    "output_files = [f for f in os.listdir(OUTPUT_DIR_BASIC) \n",
    "                if f.endswith('.txt') and 'concatenated' not in f]\n",
    "\n",
    "print(f\"Output files created: {output_files}\")\n",
    "\n",
    "# Load the first file\n",
    "test_file_path = os.path.join(OUTPUT_DIR_BASIC, output_files[0])\n",
    "print(f\"\\nLoading: {output_files[0]}\")\n",
    "\n",
    "test_df = pd.read_csv(test_file_path, sep='\\t', encoding='utf-8')\n",
    "print(f\"Rows loaded: {len(test_df)}\")\n",
    "print(f\"Columns: {test_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Required Columns\n",
      "----------------------------------------\n",
      "✓ participant\n",
      "✓ content\n",
      "✓ token\n",
      "✓ lemma\n",
      "✓ tagged_token\n",
      "✓ tagged_lemma\n",
      "✓ file\n",
      "\n",
      "Result: ✓ PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Verify all columns are present\n",
    "required_cols = ['participant', 'content', 'token', 'lemma', 'tagged_token', 'tagged_lemma', 'file']\n",
    "\n",
    "print(\"Test 1: Required Columns\")\n",
    "print(\"-\" * 40)\n",
    "for col in required_cols:\n",
    "    present = col in test_df.columns\n",
    "    status = \"✓\" if present else \"✗\"\n",
    "    print(f\"{status} {col}\")\n",
    "\n",
    "all_present = all(col in test_df.columns for col in required_cols)\n",
    "print(f\"\\nResult: {'✓ PASSED' if all_present else '✗ FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2: Data Types (should be strings)\n",
      "----------------------------------------\n",
      "✓ token: str\n",
      "✓ lemma: str\n",
      "✓ tagged_token: str\n",
      "✓ tagged_lemma: str\n",
      "\n",
      "Result: ✓ PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Verify data types (should be strings)\n",
    "list_columns = ['token', 'lemma', 'tagged_token', 'tagged_lemma']\n",
    "\n",
    "print(\"Test 2: Data Types (should be strings)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "all_strings = True\n",
    "for col in list_columns:\n",
    "    if col in test_df.columns:\n",
    "        first_val = test_df[col].iloc[0]\n",
    "        is_string = isinstance(first_val, str)\n",
    "        status = \"✓\" if is_string else \"✗\"\n",
    "        print(f\"{status} {col}: {type(first_val).__name__}\")\n",
    "        if not is_string:\n",
    "            all_strings = False\n",
    "\n",
    "print(f\"\\nResult: {'✓ PASSED' if all_strings else '✗ FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3: ast.literal_eval Compatibility\n",
      "----------------------------------------\n",
      "✓ token: Parses to list\n",
      "  Sample: ['that', 'was', 'fun']...\n",
      "✓ lemma: Parses to list\n",
      "  Sample: ['that', 'be', 'fun']...\n",
      "✓ tagged_token: Parses to list\n",
      "  Sample: [('that', 'DT'), ('was', 'VBD'), ('fun', 'NN')]...\n",
      "✓ tagged_lemma: Parses to list\n",
      "  Sample: [('that', 'DT'), ('be', 'VB'), ('fun', 'NN')]...\n",
      "\n",
      "Result: ✓ PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Verify ast.literal_eval compatibility\n",
    "print(\"Test 3: ast.literal_eval Compatibility\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "all_parseable = True\n",
    "for col in list_columns:\n",
    "    if col in test_df.columns:\n",
    "        try:\n",
    "            parsed = ast.literal_eval(test_df[col].iloc[0])\n",
    "            print(f\"✓ {col}: Parses to {type(parsed).__name__}\")\n",
    "            print(f\"  Sample: {str(parsed)[:60]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {col}: Parse failed - {e}\")\n",
    "            all_parseable = False\n",
    "\n",
    "print(f\"\\nResult: {'✓ PASSED' if all_parseable else '✗ FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4: POS Tag Format\n",
      "----------------------------------------\n",
      "✓ tagged_token: Correct format\n",
      "  Sample: ('that', 'DT') (word, POS)\n",
      "✓ tagged_lemma: Correct format\n",
      "  Sample: ('that', 'DT') (word, POS)\n",
      "\n",
      "Result: ✓ PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Verify POS tag tuple format\n",
    "print(\"Test 4: POS Tag Format\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "correct_format = True\n",
    "for col in ['tagged_token', 'tagged_lemma']:\n",
    "    if col in test_df.columns:\n",
    "        try:\n",
    "            parsed = ast.literal_eval(test_df[col].iloc[0])\n",
    "            if parsed:\n",
    "                is_tuple = isinstance(parsed[0], tuple)\n",
    "                correct_length = len(parsed[0]) == 2 if is_tuple else False\n",
    "                \n",
    "                if is_tuple and correct_length:\n",
    "                    print(f\"✓ {col}: Correct format\")\n",
    "                    print(f\"  Sample: {parsed[0]} (word, POS)\")\n",
    "                else:\n",
    "                    print(f\"✗ {col}: Incorrect format\")\n",
    "                    correct_format = False\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {col}: Format check failed - {e}\")\n",
    "            correct_format = False\n",
    "\n",
    "print(f\"\\nResult: {'✓ PASSED' if correct_format else '✗ FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 1 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1 SUMMARY: Basic Preprocessing\n",
      "============================================================\n",
      "\n",
      "✓ TEST 1 PASSED: Basic preprocessing works correctly!\n",
      "\n",
      "Output format is compatible with alignment analysis.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 1 SUMMARY: Basic Preprocessing\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test1_passed = all_present and all_strings and all_parseable and correct_format\n",
    "\n",
    "if test1_passed:\n",
    "    print(\"\\n✓ TEST 1 PASSED: Basic preprocessing works correctly!\")\n",
    "    print(\"\\nOutput format is compatible with alignment analysis.\")\n",
    "else:\n",
    "    print(\"\\n✗ TEST 1 FAILED: Some checks did not pass.\")\n",
    "    print(\"Please review the test results above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 2: Preprocessing with spaCy\n",
    "\n",
    "Test preprocessing with spaCy POS tagger (100x faster than Stanford)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ spaCy is installed\n",
      "Note: Model will be auto-downloaded by prepare_transcripts() if needed\n"
     ]
    }
   ],
   "source": [
    "# Check if spaCy is available\n",
    "try:\n",
    "    import spacy\n",
    "    print(\"✓ spaCy is installed\")\n",
    "    print(\"Note: Model will be auto-downloaded by prepare_transcripts() if needed\")\n",
    "    spacy_available = True\n",
    "except ImportError:\n",
    "    print(\"✗ spaCy not installed\")\n",
    "    print(\"Install with: pip install spacy\")\n",
    "    print(\"Will skip spaCy tests\")\n",
    "    spacy_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Preprocessing with spaCy\n",
      "============================================================\n",
      "Downloading required NLTK resources...\n",
      "  - Downloading wordnet...\n",
      "    ✓ wordnet downloaded successfully\n",
      "  - Downloading omw-1.4...\n",
      "    ✓ omw-1.4 downloaded successfully\n",
      "NLTK resources ready!\n",
      "\n",
      "\n",
      "Found 20 files to process\n",
      "Output directory: ./test_output_spacy\n",
      "\n",
      "============================================================\n",
      "Processing: time197-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 76 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 76/76 [00:00<00:00, 1117.78it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 76/76 [00:00<00:00, 1171.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time197-cond1.txt\n",
      "     Rows: 76\n",
      "============================================================\n",
      "Processing: time202-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 92 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 92/92 [00:00<00:00, 1020.33it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 92/92 [00:00<00:00, 1067.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time202-cond1.txt\n",
      "     Rows: 92\n",
      "============================================================\n",
      "Processing: time191-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 99 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 99/99 [00:00<00:00, 1133.27it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 99/99 [00:00<00:00, 1165.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time191-cond1.txt\n",
      "     Rows: 99\n",
      "============================================================\n",
      "Processing: time209-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 98 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 98/98 [00:00<00:00, 1081.86it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 98/98 [00:00<00:00, 1089.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time209-cond1.txt\n",
      "     Rows: 98\n",
      "============================================================\n",
      "Processing: time210-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 100 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 100/100 [00:00<00:00, 1156.98it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 100/100 [00:00<00:00, 1161.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time210-cond1.txt\n",
      "     Rows: 100\n",
      "============================================================\n",
      "Processing: time204-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 143 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 143/143 [00:00<00:00, 1066.18it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 143/143 [00:00<00:00, 1104.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time204-cond1.txt\n",
      "     Rows: 143\n",
      "============================================================\n",
      "Processing: time196-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 66 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 66/66 [00:00<00:00, 1050.59it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 66/66 [00:00<00:00, 1076.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time196-cond1.txt\n",
      "     Rows: 66\n",
      "============================================================\n",
      "Processing: time203-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 90 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 90/90 [00:00<00:00, 1070.49it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 90/90 [00:00<00:00, 1059.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time203-cond1.txt\n",
      "     Rows: 90\n",
      "============================================================\n",
      "Processing: time208-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 86 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 86/86 [00:00<00:00, 946.54it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 86/86 [00:00<00:00, 990.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time208-cond1.txt\n",
      "     Rows: 86\n",
      "============================================================\n",
      "Processing: time205-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 106 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 106/106 [00:00<00:00, 1012.47it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 106/106 [00:00<00:00, 1050.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time205-cond1.txt\n",
      "     Rows: 106\n",
      "============================================================\n",
      "Processing: time195-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 90 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 90/90 [00:00<00:00, 976.91it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 90/90 [00:00<00:00, 1072.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time195-cond1.txt\n",
      "     Rows: 90\n",
      "============================================================\n",
      "Processing: time198-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 89 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 89/89 [00:00<00:00, 1019.87it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 89/89 [00:00<00:00, 1019.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time198-cond1.txt\n",
      "     Rows: 89\n",
      "============================================================\n",
      "Processing: time200-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 78 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 78/78 [00:00<00:00, 960.39it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 78/78 [00:00<00:00, 982.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time200-cond1.txt\n",
      "     Rows: 78\n",
      "============================================================\n",
      "Processing: time193-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 95 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 95/95 [00:00<00:00, 1037.26it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 95/95 [00:00<00:00, 1082.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time193-cond1.txt\n",
      "     Rows: 95\n",
      "============================================================\n",
      "Processing: time206-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 97 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 97/97 [00:00<00:00, 1038.35it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 97/97 [00:00<00:00, 1052.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time206-cond1.txt\n",
      "     Rows: 97\n",
      "============================================================\n",
      "Processing: time194-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 77 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 77/77 [00:00<00:00, 997.18it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 77/77 [00:00<00:00, 1032.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time194-cond1.txt\n",
      "     Rows: 77\n",
      "============================================================\n",
      "Processing: time199-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 87 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 87/87 [00:00<00:00, 1023.63it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 87/87 [00:00<00:00, 1053.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time199-cond1.txt\n",
      "     Rows: 87\n",
      "============================================================\n",
      "Processing: time201-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 90 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 90/90 [00:00<00:00, 1052.24it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 90/90 [00:00<00:00, 1114.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time201-cond1.txt\n",
      "     Rows: 90\n",
      "============================================================\n",
      "Processing: time192-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 67 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 67/67 [00:00<00:00, 1045.79it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 67/67 [00:00<00:00, 1085.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time192-cond1.txt\n",
      "     Rows: 67\n",
      "============================================================\n",
      "Processing: time207-cond1.txt\n",
      "============================================================\n",
      "  1. Cleaning text...\n",
      "  2. Merging adjacent turns...\n",
      "  3. Tokenizing...\n",
      "  4. Lemmatizing...\n",
      "  5. Applying POS tagging...\n",
      "Initializing spaCy POS tagger...\n",
      "Loaded spaCy model: en_core_web_sm\n",
      "spaCy tagger initialized (disabled: ['parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
      "Converting tokens and lemmas to string representations...\n",
      "Applying NLTK POS tagging...\n",
      "NLTK POS tagging complete\n",
      "Applying spaCy POS tagging to 106 utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy tagging tokens: 100%|██████████| 106/106 [00:00<00:00, 961.05it/s]\n",
      "spaCy tagging lemmas: 100%|██████████| 106/106 [00:00<00:00, 1099.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy POS tagging complete\n",
      "  6. Saved: time207-cond1.txt\n",
      "     Rows: 106\n",
      "\n",
      "============================================================\n",
      "Saved concatenated dataframe: align_concatenated_dataframe.txt\n",
      "Total rows: 1832\n",
      "============================================================\n",
      "\n",
      "Processing complete!\n",
      "\n",
      "Summary:\n",
      "  - Files processed: 20\n",
      "  - Total utterances: 1832\n",
      "  - Output directory: ./test_output_spacy\n",
      "\n",
      "✓ Preprocessing with spaCy complete!\n",
      "Total utterances processed: 1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Only run if spaCy is available\n",
    "if spacy_available:\n",
    "    print(\"=\"*60)\n",
    "    print(\"TEST 2: Preprocessing with spaCy\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Run preprocessing with spaCy\n",
    "    results_spacy = prepare_transcripts(\n",
    "        input_files=CHILDES_DATA_DIR,\n",
    "        output_file_directory=OUTPUT_DIR_SPACY,\n",
    "        run_spell_check=False,\n",
    "        minwords=2,\n",
    "        add_additional_tags=True,\n",
    "        tagger_type='spacy',  # Use spaCy\n",
    "        input_as_directory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Preprocessing with spaCy complete!\")\n",
    "    print(f\"Total utterances processed: {len(results_spacy)}\")\n",
    "else:\n",
    "    print(\"\\nSkipping spaCy test (spaCy not available)\")\n",
    "    results_spacy = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 2 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output columns:\n",
      "  - participant\n",
      "  - content\n",
      "  - token\n",
      "  - lemma\n",
      "  - tagged_token\n",
      "  - tagged_lemma\n",
      "  - tagged_spacy_token\n",
      "  - tagged_spacy_lemma\n",
      "  - file\n",
      "\n",
      "✓ spaCy tagging columns present (tagged_spacy_token, tagged_spacy_lemma)\n",
      "\n",
      "Sample spaCy tags:\n",
      "  1. ('that', 'DT')\n",
      "  2. ('was', 'VBD')\n",
      "  3. ('fun', 'JJ')\n"
     ]
    }
   ],
   "source": [
    "# Examine spaCy output (if available)\n",
    "if results_spacy is not None:\n",
    "    print(\"Output columns:\")\n",
    "    for col in results_spacy.columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    # Check for spaCy-specific columns\n",
    "    has_spacy_cols = 'tagged_spacy_token' in results_spacy.columns and 'tagged_spacy_lemma' in results_spacy.columns\n",
    "    \n",
    "    if has_spacy_cols:\n",
    "        print(\"\\n✓ spaCy tagging columns present (tagged_spacy_token, tagged_spacy_lemma)\")\n",
    "        \n",
    "        # Show sample spaCy tags\n",
    "        sample_spacy_tag = ast.literal_eval(results_spacy['tagged_spacy_token'].iloc[0])\n",
    "        print(f\"\\nSample spaCy tags:\")\n",
    "        for i, (word, tag) in enumerate(sample_spacy_tag[:5]):\n",
    "            print(f\"  {i+1}. ('{word}', '{tag}')\")\n",
    "    else:\n",
    "        print(\"\\n✗ spaCy tagging columns missing!\")\n",
    "    \n",
    "    results_spacy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2 SUMMARY: spaCy Preprocessing\n",
      "============================================================\n",
      "\n",
      "✓ TEST 2 PASSED: spaCy preprocessing works correctly!\n",
      "\n",
      "spaCy tags are being generated and stored properly.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 2 SUMMARY: spaCy Preprocessing\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if results_spacy is not None:\n",
    "    test2_passed = has_spacy_cols and len(results_spacy) > 0\n",
    "    \n",
    "    if test2_passed:\n",
    "        print(\"\\n✓ TEST 2 PASSED: spaCy preprocessing works correctly!\")\n",
    "        print(\"\\nspaCy tags are being generated and stored properly.\")\n",
    "    else:\n",
    "        print(\"\\n✗ TEST 2 FAILED: spaCy preprocessing had issues.\")\n",
    "else:\n",
    "    print(\"\\n⊘ TEST 2 SKIPPED: spaCy not available\")\n",
    "    test2_passed = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare NLTK tags vs spaCy tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: NLTK vs spaCy POS Tags\n",
      "============================================================\n",
      "Utterance: that was fun\n",
      "\n",
      "Word            NLTK Tag   spaCy Tag  Same?     \n",
      "--------------------------------------------------\n",
      "that            DT         DT         ✓         \n",
      "was             VBD        VBD        ✓         \n",
      "fun             NN         JJ         ✗         \n",
      "\n",
      "Agreement: 2/3 (66.7%)\n"
     ]
    }
   ],
   "source": [
    "# Compare NLTK tags vs spaCy tags for same utterance\n",
    "if results_spacy is not None:\n",
    "    print(\"Comparison: NLTK vs spaCy POS Tags\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sample_row = results_spacy.iloc[0]\n",
    "    \n",
    "    nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "    spacy_tags = ast.literal_eval(sample_row['tagged_spacy_token'])\n",
    "    \n",
    "    print(f\"Utterance: {sample_row['content']}\\n\")\n",
    "    print(f\"{'Word':<15} {'NLTK Tag':<10} {'spaCy Tag':<10} {'Same?':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for (word_n, tag_n), (word_s, tag_s) in zip(nltk_tags, spacy_tags):\n",
    "        same = \"✓\" if tag_n == tag_s else \"✗\"\n",
    "        print(f\"{word_n:<15} {tag_n:<10} {tag_s:<10} {same:<10}\")\n",
    "    \n",
    "    # Calculate agreement\n",
    "    agreements = sum(1 for (_, t1), (_, t2) in zip(nltk_tags, spacy_tags) if t1 == t2)\n",
    "    total = len(nltk_tags)\n",
    "    agreement_pct = (agreements / total * 100) if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nAgreement: {agreements}/{total} ({agreement_pct:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPREHENSIVE COMPARISON: NLTK vs spaCy POS Tags\n",
      "============================================================\n",
      "\n",
      "📊 OVERALL STATISTICS:\n",
      "   Total tokens compared: 21927\n",
      "   Agreements: 17950\n",
      "   Disagreements: 3977\n",
      "   Overall Agreement: 81.9%\n",
      "\n",
      "   Per-utterance agreement:\n",
      "      Mean: 81.5%\n",
      "      Median: 83.3%\n",
      "      Min: 0.0%\n",
      "      Max: 100.0%\n",
      "\n",
      "============================================================\n",
      "DETAILED EXAMPLES (First 3 utterances with >5 words)\n",
      "============================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: dad you should have climbed the cliffs with us\n",
      "\n",
      "Word            NLTK       spaCy      Match   \n",
      "------------------------------------------------\n",
      "dad             NN         NN         ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "should          MD         MD         ✓       \n",
      "have            VB         VB         ✓       \n",
      "climbed         VBD        VBN        ✗       \n",
      "the             DT         DT         ✓       \n",
      "cliffs          NNS        NNS        ✓       \n",
      "with            IN         IN         ✓       \n",
      "us              PRP        PRP        ✓       \n",
      "\n",
      "Agreement: 8/9 (88.9%)\n",
      "Disagreements: 1\n",
      "  • 'climbed': NLTK=VBD, spaCy=VBN\n",
      "\n",
      "--- Example 2 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: did you have fun fishing i hope that we go there another time\n",
      "\n",
      "Word            NLTK       spaCy      Match   \n",
      "------------------------------------------------\n",
      "did             VBD        VBD        ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "have            VBP        VB         ✗       \n",
      "fun             VBN        NN         ✗       \n",
      "fishing         NN         NN         ✓       \n",
      "i               NN         PRP        ✗       \n",
      "hope            VBP        VBP        ✓       \n",
      "that            IN         IN         ✓       \n",
      "we              PRP        PRP        ✓       \n",
      "go              VBP        VBP        ✓       \n",
      "there           RB         RB         ✓       \n",
      "another         DT         DT         ✓       \n",
      "time            NN         NN         ✓       \n",
      "\n",
      "Agreement: 10/13 (76.9%)\n",
      "Disagreements: 3\n",
      "  • 'have': NLTK=VBP, spaCy=VB\n",
      "  • 'fun': NLTK=VBN, spaCy=NN\n",
      "  • 'i': NLTK=NN, spaCy=PRP\n",
      "\n",
      "--- Example 3 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: are we dad i'm glad momma while you're in there can you get me two crackers two graham crackers with peanut butter\n",
      "\n",
      "Word            NLTK       spaCy      Match   \n",
      "------------------------------------------------\n",
      "are             VBP        VBP        ✓       \n",
      "we              PRP        PRP        ✓       \n",
      "dad             VBP        NN         ✗       \n",
      "i               JJ         PRP        ✗       \n",
      "am              VBP        VBP        ✓       \n",
      "glad            JJ         JJ         ✓       \n",
      "momma           NN         NN         ✓       \n",
      "while           IN         IN         ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "are             VBP        VBP        ✓       \n",
      "in              IN         IN         ✓       \n",
      "there           EX         EX         ✓       \n",
      "can             MD         MD         ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "get             VB         VB         ✓       \n",
      "me              PRP        PRP        ✓       \n",
      "two             CD         CD         ✓       \n",
      "crackers        NNS        NNS        ✓       \n",
      "two             CD         CD         ✓       \n",
      "graham          JJ         NN         ✗       \n",
      "crackers        NNS        NNS        ✓       \n",
      "with            IN         IN         ✓       \n",
      "peanut          NN         NN         ✓       \n",
      "butter          NN         NN         ✓       \n",
      "\n",
      "Agreement: 21/24 (87.5%)\n",
      "Disagreements: 3\n",
      "  • 'dad': NLTK=VBP, spaCy=NN\n",
      "  • 'i': NLTK=JJ, spaCy=PRP\n",
      "  • 'graham': NLTK=JJ, spaCy=NN\n",
      "\n",
      "============================================================\n",
      "MOST COMMON TAG DISAGREEMENTS\n",
      "============================================================\n",
      "\n",
      "Top 10 tag disagreement patterns:\n",
      " 1. NLTK:NN vs spaCy:PRP           (n=661) Examples: i, one, em\n",
      " 2. NLTK:NN vs spaCy:NNP           (n=208) Examples: scab, jean, amy\n",
      " 3. NLTK:NN vs spaCy:UH            (n=174) Examples: gosh, wow, hey\n",
      " 4. NLTK:JJ vs spaCy:PRP           (n=169) Examples: i, mine, em\n",
      " 5. NLTK:NNS vs spaCy:PRP          (n=144) Examples: yours, ya, ours\n",
      " 6. NLTK:VBP vs spaCy:VB           (n=121) Examples: get, see, play\n",
      " 7. NLTK:JJ vs spaCy:NN            (n=119) Examples: couple, needle, outside\n",
      " 8. NLTK:VB vs spaCy:PRP           (n=111) Examples: i, myself, em\n",
      " 9. NLTK:DT vs spaCy:UH            (n=100) Examples: no\n",
      "10. NLTK:NN vs spaCy:VB            (n= 97) Examples: see, get, rip\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare NLTK tags vs spaCy tags across ALL utterances\n",
    "if results_spacy is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPREHENSIVE COMPARISON: NLTK vs spaCy POS Tags\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_agreements = 0\n",
    "    total_tokens = 0\n",
    "    per_utterance_agreements = []\n",
    "    \n",
    "    # Calculate agreement across all utterances\n",
    "    for idx in range(len(results_spacy)):\n",
    "        sample_row = results_spacy.iloc[idx]\n",
    "        \n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        spacy_tags = ast.literal_eval(sample_row['tagged_spacy_token'])\n",
    "        \n",
    "        if nltk_tags and spacy_tags and len(nltk_tags) == len(spacy_tags):\n",
    "            agreements = sum(1 for (_, t1), (_, t2) in zip(nltk_tags, spacy_tags) if t1 == t2)\n",
    "            total_agreements += agreements\n",
    "            total_tokens += len(nltk_tags)\n",
    "            \n",
    "            # Track per-utterance agreement\n",
    "            utterance_pct = (agreements / len(nltk_tags)) * 100\n",
    "            per_utterance_agreements.append(utterance_pct)\n",
    "    \n",
    "    # Overall statistics\n",
    "    overall_agreement_pct = (total_agreements / total_tokens * 100) if total_tokens > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📊 OVERALL STATISTICS:\")\n",
    "    print(f\"   Total tokens compared: {total_tokens}\")\n",
    "    print(f\"   Agreements: {total_agreements}\")\n",
    "    print(f\"   Disagreements: {total_tokens - total_agreements}\")\n",
    "    print(f\"   Overall Agreement: {overall_agreement_pct:.1f}%\")\n",
    "    \n",
    "    if per_utterance_agreements:\n",
    "        import numpy as np\n",
    "        print(f\"\\n   Per-utterance agreement:\")\n",
    "        print(f\"      Mean: {np.mean(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Median: {np.median(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Min: {np.min(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Max: {np.max(per_utterance_agreements):.1f}%\")\n",
    "    \n",
    "    # Show detailed examples\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED EXAMPLES (First 3 utterances with >5 words)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    examples_shown = 0\n",
    "    for idx in range(len(results_spacy)):\n",
    "        if examples_shown >= 3:\n",
    "            break\n",
    "            \n",
    "        sample_row = results_spacy.iloc[idx]\n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        spacy_tags = ast.literal_eval(sample_row['tagged_spacy_token'])\n",
    "        \n",
    "        if len(nltk_tags) > 5 and len(spacy_tags) > 5:\n",
    "            examples_shown += 1\n",
    "            \n",
    "            print(f\"\\n--- Example {examples_shown} ---\")\n",
    "            print(f\"Source: {sample_row.get('file', 'unknown')}\")\n",
    "            print(f\"Participant: {sample_row.get('participant', 'unknown')}\")\n",
    "            print(f\"Utterance: {sample_row['content']}\\n\")\n",
    "            print(f\"{'Word':<15} {'NLTK':<10} {'spaCy':<10} {'Match':<8}\")\n",
    "            print(\"-\" * 48)\n",
    "            \n",
    "            agreements = 0\n",
    "            disagreements = []\n",
    "            \n",
    "            for (word_n, tag_n), (word_s, tag_s) in zip(nltk_tags, spacy_tags):\n",
    "                match = \"✓\" if tag_n == tag_s else \"✗\"\n",
    "                print(f\"{word_n:<15} {tag_n:<10} {tag_s:<10} {match:<8}\")\n",
    "                \n",
    "                if tag_n == tag_s:\n",
    "                    agreements += 1\n",
    "                else:\n",
    "                    disagreements.append((word_n, tag_n, tag_s))\n",
    "            \n",
    "            total = len(nltk_tags)\n",
    "            print(f\"\\nAgreement: {agreements}/{total} ({100*agreements/total:.1f}%)\")\n",
    "            \n",
    "            if disagreements:\n",
    "                print(f\"Disagreements: {len(disagreements)}\")\n",
    "                for word, nltk_tag, spacy_tag in disagreements[:3]:  # Show first 3\n",
    "                    print(f\"  • '{word}': NLTK={nltk_tag}, spaCy={spacy_tag}\")\n",
    "    \n",
    "    # Identify most common disagreements\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MOST COMMON TAG DISAGREEMENTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    disagreement_counts = {}\n",
    "    for idx in range(len(results_spacy)):\n",
    "        sample_row = results_spacy.iloc[idx]\n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        spacy_tags = ast.literal_eval(sample_row['tagged_spacy_token'])\n",
    "        \n",
    "        if nltk_tags and spacy_tags:\n",
    "            for (word, t1), (_, t2) in zip(nltk_tags, spacy_tags):\n",
    "                if t1 != t2:\n",
    "                    key = f\"NLTK:{t1} vs spaCy:{t2}\"\n",
    "                    if key not in disagreement_counts:\n",
    "                        disagreement_counts[key] = []\n",
    "                    disagreement_counts[key].append(word)\n",
    "    \n",
    "    # Show top 10 disagreements\n",
    "    if disagreement_counts:\n",
    "        sorted_disagreements = sorted(disagreement_counts.items(), \n",
    "                                     key=lambda x: len(x[1]), \n",
    "                                     reverse=True)\n",
    "        \n",
    "        print(\"\\nTop 10 tag disagreement patterns:\")\n",
    "        for i, (pattern, words) in enumerate(sorted_disagreements[:10], 1):\n",
    "            example_words = ', '.join(list(set(words))[:3])  # Show up to 3 unique examples\n",
    "            print(f\"{i:2}. {pattern:<30} (n={len(words):3}) Examples: {example_words}\")\n",
    "    else:\n",
    "        print(\"\\n✓ Perfect agreement! No disagreements found.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 3: Preprocessing with Stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Checking Java installation...\n",
      "----------------------------------------\n",
      "✓ Java is installed: java version \"1.8.0_471\"\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Step 1: Check if Java is installed\n",
    "print(\"\\n1. Checking Java installation...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "java_available = False\n",
    "try:\n",
    "    result = subprocess.run(['java', '-version'], \n",
    "                          capture_output=True, \n",
    "                          text=True, \n",
    "                          timeout=5)\n",
    "    \n",
    "    # Check both stderr and stdout for Java version info\n",
    "    output = result.stderr + result.stdout\n",
    "    \n",
    "    # Java typically outputs to stderr, and should contain \"version\"\n",
    "    # Check return code AND output content\n",
    "    if result.returncode == 0 and ('version' in output.lower() or 'openjdk' in output.lower()):\n",
    "        # Extract version line (usually first line)\n",
    "        version_lines = [line for line in output.split('\\n') if line.strip()]\n",
    "        if version_lines:\n",
    "            java_version = version_lines[0]\n",
    "            # Double-check it's not an error message\n",
    "            if 'unable to locate' not in java_version.lower() and 'not found' not in java_version.lower():\n",
    "                print(f\"✓ Java is installed: {java_version}\")\n",
    "                java_available = True\n",
    "            else:\n",
    "                print(\"✗ Java not found\")\n",
    "                print(f\"  Error: {java_version}\")\n",
    "    else:\n",
    "        print(\"✗ Java not found or not working properly\")\n",
    "        if output.strip():\n",
    "            print(f\"  Output: {output.strip()[:100]}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"✗ Java command not found\")\n",
    "    print(\"  Java is not installed or not in PATH\")\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"✗ Java check timed out\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error checking Java: {e}\")\n",
    "\n",
    "if not java_available:\n",
    "    print(\"\\n  Stanford POS Tagger requires Java to run\")\n",
    "    print(\"  Install Java from:\")\n",
    "    print(\"    - macOS: https://www.java.com/en/download/\")\n",
    "    print(\"    - macOS (alternative): brew install openjdk\")\n",
    "    print(\"    - Linux: sudo apt-get install default-jdk\")\n",
    "    print(\"    - Windows: https://www.java.com/en/download/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Checking Stanford POS Tagger files...\n",
      "----------------------------------------\n",
      "✗ Stanford POS Tagger not found in common locations\n",
      "\n",
      "To use Stanford tagger:\n",
      "  1. Download from: https://nlp.stanford.edu/software/tagger.shtml#Download\n",
      "  2. Extract to a known location\n",
      "  3. Update the paths below\n",
      "\n",
      "Common locations checked:\n",
      "  - /Users/ndd697/stanford-postagger\n",
      "  - /Users/ndd697/Downloads/stanford-postagger-full-2020-11-17\n",
      "  - /usr/local/stanford-postagger\n",
      "  - ./stanford-postagger\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check for Stanford POS Tagger files\n",
    "print(\"\\n2. Checking Stanford POS Tagger files...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "stanford_available = False\n",
    "stanford_pos_path = None\n",
    "stanford_language_path = None\n",
    "\n",
    "if java_available:\n",
    "    # Common locations where users might have Stanford tagger\n",
    "    common_locations = [\n",
    "        os.path.expanduser(\"~/stanford-postagger\"),\n",
    "        os.path.expanduser(\"~/Downloads/stanford-postagger-full-2020-11-17\"),\n",
    "        \"/usr/local/stanford-postagger\",\n",
    "        \"./stanford-postagger\",\n",
    "    ]\n",
    "    \n",
    "    # Check if any common location exists\n",
    "    for location in common_locations:\n",
    "        if os.path.exists(location):\n",
    "            # Check for required files\n",
    "            jar_path = os.path.join(location, \"stanford-postagger.jar\")\n",
    "            model_path = os.path.join(location, \"models/english-left3words-distsim.tagger\")\n",
    "            \n",
    "            if os.path.exists(jar_path) and os.path.exists(model_path):\n",
    "                stanford_pos_path = location\n",
    "                stanford_language_path = \"models/english-left3words-distsim.tagger\"\n",
    "                stanford_available = True\n",
    "                print(f\"✓ Found Stanford tagger at: {location}\")\n",
    "                print(f\"  JAR: {jar_path}\")\n",
    "                print(f\"  Model: {model_path}\")\n",
    "                break\n",
    "    \n",
    "    if not stanford_available:\n",
    "        print(\"✗ Stanford POS Tagger not found in common locations\")\n",
    "        print(\"\\nTo use Stanford tagger:\")\n",
    "        print(\"  1. Download from: https://nlp.stanford.edu/software/tagger.shtml#Download\")\n",
    "        print(\"  2. Extract to a known location\")\n",
    "        print(\"  3. Update the paths below\")\n",
    "        print(\"\\nCommon locations checked:\")\n",
    "        for loc in common_locations:\n",
    "            print(f\"  - {loc}\")\n",
    "else:\n",
    "    print(\"⊘ Skipping (Java not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Path Configuration\n",
      "----------------------------------------\n",
      "\n",
      "⚠️  Stanford tagger not auto-detected.\n",
      "If you have Stanford tagger installed, specify paths below:\n",
      "\n",
      "Example paths:\n",
      "  stanford_pos_path = '/Users/yourname/stanford-postagger-full-2020-11-17'\n",
      "  stanford_language_path = 'models/english-left3words-distsim.tagger'\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Manual path configuration (if not auto-detected)\n",
    "print(\"\\n3. Path Configuration\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if java_available and not stanford_available:\n",
    "    print(\"\\n⚠️  Stanford tagger not auto-detected.\")\n",
    "    print(\"If you have Stanford tagger installed, specify paths below:\")\n",
    "    print(\"\\nExample paths:\")\n",
    "    print(\"  stanford_pos_path = '/Users/yourname/stanford-postagger-full-2020-11-17'\")\n",
    "    print(\"  stanford_language_path = 'models/english-left3words-distsim.tagger'\")\n",
    "    \n",
    "    # Uncomment and update these lines if you have Stanford tagger installed:\n",
    "    # stanford_pos_path = \"/path/to/your/stanford-postagger\"\n",
    "    # stanford_language_path = \"models/english-left3words-distsim.tagger\"\n",
    "    # stanford_available = True\n",
    "    \n",
    "    if stanford_pos_path and stanford_language_path:\n",
    "        # Validate the paths\n",
    "        jar_path = os.path.join(stanford_pos_path, \"stanford-postagger.jar\")\n",
    "        model_path = os.path.join(stanford_pos_path, stanford_language_path)\n",
    "        \n",
    "        if os.path.exists(jar_path) and os.path.exists(model_path):\n",
    "            stanford_available = True\n",
    "            print(f\"✓ Manual configuration successful\")\n",
    "        else:\n",
    "            print(f\"✗ Invalid paths:\")\n",
    "            if not os.path.exists(jar_path):\n",
    "                print(f\"  JAR not found: {jar_path}\")\n",
    "            if not os.path.exists(model_path):\n",
    "                print(f\"  Model not found: {model_path}\")\n",
    "            stanford_available = False\n",
    "elif stanford_available:\n",
    "    print(f\"✓ Using auto-detected paths:\")\n",
    "    print(f\"  Base: {stanford_pos_path}\")\n",
    "    print(f\"  Model: {stanford_language_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MANUALLY ADD PATHS HERE IF NEEDED ##\n",
    "# Example manual configuration (uncomment and set your paths)\n",
    "stanford_pos_path = '/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/sandbox-prepare/stanford-postagger-full-2020-11-17'\n",
    "stanford_language_path = '/Users/ndd697/Desktop/Github-Projects/llm-linguistic-alignment/sandbox-prepare/stanford-postagger-full-2020-11-17/models/english-left3words-distsim.tagger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Run Stanford tagging (if available)\n",
    "print(\"\\n4. Test Results\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# RE-VALIDATE: Check if paths were manually set after Step 3\n",
    "if not stanford_available and 'stanford_pos_path' in locals() and 'stanford_language_path' in locals():\n",
    "    if stanford_pos_path is not None and stanford_language_path is not None:\n",
    "        print(\"\\n🔄 Detected manually configured paths. Validating...\")\n",
    "        \n",
    "        # Normalize paths\n",
    "        stanford_pos_path = os.path.normpath(os.path.expanduser(stanford_pos_path))\n",
    "        stanford_language_path = os.path.normpath(stanford_language_path)\n",
    "        \n",
    "        # Check if stanford_language_path is absolute or relative\n",
    "        if os.path.isabs(stanford_language_path):\n",
    "            # It's an absolute path, use it directly\n",
    "            model_path = stanford_language_path\n",
    "        else:\n",
    "            # It's relative to stanford_pos_path\n",
    "            model_path = os.path.join(stanford_pos_path, stanford_language_path)\n",
    "        \n",
    "        jar_path = os.path.join(stanford_pos_path, \"stanford-postagger.jar\")\n",
    "        \n",
    "        print(f\"  Checking JAR: {jar_path}\")\n",
    "        print(f\"  Checking Model: {model_path}\")\n",
    "        \n",
    "        if os.path.exists(jar_path) and os.path.exists(model_path):\n",
    "            stanford_available = True\n",
    "            print(f\"  ✓ Manual configuration validated!\")\n",
    "            print(f\"  ✓ Found JAR: {os.path.basename(jar_path)}\")\n",
    "            print(f\"  ✓ Found Model: {os.path.basename(model_path)}\")\n",
    "            \n",
    "            # Update stanford_language_path to be relative if it was given as absolute\n",
    "            if os.path.isabs(stanford_language_path):\n",
    "                # Convert to relative path from stanford_pos_path\n",
    "                try:\n",
    "                    stanford_language_path = os.path.relpath(model_path, stanford_pos_path)\n",
    "                    print(f\"  ℹ️  Converted to relative path: {stanford_language_path}\")\n",
    "                except ValueError:\n",
    "                    # Can't make relative (e.g., different drives on Windows)\n",
    "                    print(f\"  ℹ️  Using absolute model path\")\n",
    "        else:\n",
    "            print(f\"  ✗ Validation failed:\")\n",
    "            if not os.path.exists(jar_path):\n",
    "                print(f\"    - JAR not found: {jar_path}\")\n",
    "            if not os.path.exists(model_path):\n",
    "                print(f\"    - Model not found: {model_path}\")\n",
    "            print(f\"\\n  💡 Tips:\")\n",
    "            print(f\"    - stanford_pos_path should point to the Stanford tagger directory\")\n",
    "            print(f\"    - stanford_language_path can be either:\")\n",
    "            print(f\"      • Relative: 'models/english-left3words-distsim.tagger'\")\n",
    "            print(f\"      • Absolute: '/full/path/to/models/english-left3words-distsim.tagger'\")\n",
    "\n",
    "# Now proceed with the test\n",
    "if not java_available:\n",
    "    print(\"\\n⊘ TEST 3 SKIPPED: Java not installed\")\n",
    "    print(\"Stanford tagger requires Java to run.\")\n",
    "    stanford_test_passed = None\n",
    "    \n",
    "elif not stanford_available:\n",
    "    print(\"\\n⊘ TEST 3 SKIPPED: Stanford tagger not configured\")\n",
    "    print(\"Stanford tagger files not found or paths not specified.\")\n",
    "    print(\"\\n💡 To configure manually:\")\n",
    "    print(\"   1. Make sure Java is installed\")\n",
    "    print(\"   2. Download Stanford POS Tagger from:\")\n",
    "    print(\"      https://nlp.stanford.edu/software/tagger.shtml#Download\")\n",
    "    print(\"   3. In Step 3 above, set:\")\n",
    "    print(\"      stanford_pos_path = '/path/to/stanford-postagger-full-2020-11-17'\")\n",
    "    print(\"      stanford_language_path = 'models/english-left3words-distsim.tagger'\")\n",
    "    print(\"   4. Re-run this cell (Step 4)\")\n",
    "    stanford_test_passed = None\n",
    "    \n",
    "else:\n",
    "    print(\"\\n✓ All prerequisites met. Running Stanford tagger test...\")\n",
    "    print(f\"\\nThis may take several minutes (Stanford tagger is ~100x slower than spaCy)\")\n",
    "    print(f\"Processing {len([f for f in os.listdir(CHILDES_DATA_DIR) if f.endswith('.txt')])} files...\")\n",
    "    \n",
    "    # Create output directory for Stanford test\n",
    "    OUTPUT_DIR_STANFORD = './test_output_stanford'\n",
    "    os.makedirs(OUTPUT_DIR_STANFORD, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results_stanford = prepare_transcripts(\n",
    "            input_files=CHILDES_DATA_DIR,\n",
    "            output_file_directory=OUTPUT_DIR_STANFORD,\n",
    "            run_spell_check=False,\n",
    "            minwords=2,\n",
    "            add_additional_tags=True,\n",
    "            tagger_type='stanford',  # Use Stanford\n",
    "            stanford_pos_path=stanford_pos_path,\n",
    "            stanford_language_path=stanford_language_path,\n",
    "            stanford_batch_size=50,  # Process in batches for better performance\n",
    "            input_as_directory=True\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\n✓ Stanford preprocessing complete!\")\n",
    "        print(f\"  Time taken: {processing_time:.1f} seconds ({processing_time/60:.1f} minutes)\")\n",
    "        print(f\"  Total utterances processed: {len(results_stanford)}\")\n",
    "        \n",
    "        # Check if Stanford tags were actually created\n",
    "        sample_stanford_tags = ast.literal_eval(results_stanford['tagged_stan_token'].iloc[0])\n",
    "        if sample_stanford_tags:\n",
    "            print(f\"  ✓ Stanford tags successfully generated\")\n",
    "            stanford_test_passed = True\n",
    "        else:\n",
    "            print(f\"  ✗ Stanford tags are empty\")\n",
    "            stanford_test_passed = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Stanford preprocessing failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        stanford_test_passed = False\n",
    "        results_stanford = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare NLTK tags vs Stanford Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPREHENSIVE COMPARISON: NLTK vs Stanford POS Tags\n",
      "============================================================\n",
      "\n",
      "📊 OVERALL STATISTICS:\n",
      "   Total tokens compared: 21927\n",
      "   Agreements: 18352\n",
      "   Disagreements: 3575\n",
      "   Overall Agreement: 83.7%\n",
      "\n",
      "   Per-utterance agreement:\n",
      "      Mean: 83.2%\n",
      "      Median: 85.7%\n",
      "      Min: 0.0%\n",
      "      Max: 100.0%\n",
      "\n",
      "============================================================\n",
      "DETAILED EXAMPLES (First 3 utterances with >5 words)\n",
      "============================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: dad you should have climbed the cliffs with us\n",
      "\n",
      "Word            NLTK       Stanford   Match   \n",
      "------------------------------------------------\n",
      "dad             NN         NN         ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "should          MD         MD         ✓       \n",
      "have            VB         VB         ✓       \n",
      "climbed         VBD        VBD        ✓       \n",
      "the             DT         DT         ✓       \n",
      "cliffs          NNS        NNS        ✓       \n",
      "with            IN         IN         ✓       \n",
      "us              PRP        PRP        ✓       \n",
      "\n",
      "Agreement: 9/9 (100.0%)\n",
      "\n",
      "--- Example 2 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: did you have fun fishing i hope that we go there another time\n",
      "\n",
      "Word            NLTK       Stanford   Match   \n",
      "------------------------------------------------\n",
      "did             VBD        VBD        ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "have            VBP        VB         ✗       \n",
      "fun             VBN        JJ         ✗       \n",
      "fishing         NN         NN         ✓       \n",
      "i               NN         PRP        ✗       \n",
      "hope            VBP        VBP        ✓       \n",
      "that            IN         IN         ✓       \n",
      "we              PRP        PRP        ✓       \n",
      "go              VBP        VBP        ✓       \n",
      "there           RB         RB         ✓       \n",
      "another         DT         DT         ✓       \n",
      "time            NN         NN         ✓       \n",
      "\n",
      "Agreement: 10/13 (76.9%)\n",
      "Disagreements: 3\n",
      "  • 'have': NLTK=VBP, Stanford=VB\n",
      "  • 'fun': NLTK=VBN, Stanford=JJ\n",
      "  • 'i': NLTK=NN, Stanford=PRP\n",
      "\n",
      "--- Example 3 ---\n",
      "Source: time197-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: are we dad i'm glad momma while you're in there can you get me two crackers two graham crackers with peanut butter\n",
      "\n",
      "Word            NLTK       Stanford   Match   \n",
      "------------------------------------------------\n",
      "are             VBP        VBP        ✓       \n",
      "we              PRP        PRP        ✓       \n",
      "dad             VBP        NN         ✗       \n",
      "i               JJ         PRP        ✗       \n",
      "am              VBP        VBP        ✓       \n",
      "glad            JJ         JJ         ✓       \n",
      "momma           NN         NN         ✓       \n",
      "while           IN         IN         ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "are             VBP        VBP        ✓       \n",
      "in              IN         IN         ✓       \n",
      "there           EX         EX         ✓       \n",
      "can             MD         MD         ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "get             VB         VB         ✓       \n",
      "me              PRP        PRP        ✓       \n",
      "two             CD         CD         ✓       \n",
      "crackers        NNS        NNS        ✓       \n",
      "two             CD         CD         ✓       \n",
      "graham          JJ         NN         ✗       \n",
      "crackers        NNS        NNS        ✓       \n",
      "with            IN         IN         ✓       \n",
      "peanut          NN         NN         ✓       \n",
      "butter          NN         NN         ✓       \n",
      "\n",
      "Agreement: 21/24 (87.5%)\n",
      "Disagreements: 3\n",
      "  • 'dad': NLTK=VBP, Stanford=NN\n",
      "  • 'i': NLTK=JJ, Stanford=PRP\n",
      "  • 'graham': NLTK=JJ, Stanford=NN\n",
      "\n",
      "============================================================\n",
      "MOST COMMON TAG DISAGREEMENTS (NLTK vs Stanford)\n",
      "============================================================\n",
      "\n",
      "Top 10 tag disagreement patterns:\n",
      " 1. NLTK:NN vs Stanford:PRP             (n=663) Examples: one, theirs, i\n",
      " 2. NLTK:JJ vs Stanford:PRP             (n=170) Examples: i, mine, em\n",
      " 3. NLTK:NNS vs Stanford:PRP            (n=141) Examples: ya, hers, ours\n",
      " 4. NLTK:NN vs Stanford:JJ              (n=132) Examples: hey, strange, tight\n",
      " 5. NLTK:JJ vs Stanford:NN              (n=130) Examples: couple, oven, needle\n",
      " 6. NLTK:VB vs Stanford:PRP             (n=111) Examples: mine, i, myself\n",
      " 7. NLTK:VBP vs Stanford:VB             (n=101) Examples: get, see, play\n",
      " 8. NLTK:NN vs Stanford:UH              (n= 98) Examples: yeah, okay, gosh\n",
      " 9. NLTK:TO vs Stanford:IN              (n= 96) Examples: to\n",
      "10. NLTK:VB vs Stanford:NN              (n= 91) Examples: someday, ride, china\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COMPARISON: NLTK vs Stanford POS Tags\n",
    "# ============================================================\n",
    "if results_stanford is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPREHENSIVE COMPARISON: NLTK vs Stanford POS Tags\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_agreements = 0\n",
    "    total_tokens = 0\n",
    "    per_utterance_agreements = []\n",
    "    \n",
    "    # Calculate agreement across all utterances\n",
    "    for idx in range(len(results_stanford)):\n",
    "        sample_row = results_stanford.iloc[idx]\n",
    "        \n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        stanford_tags = ast.literal_eval(sample_row['tagged_stan_token'])\n",
    "        \n",
    "        if nltk_tags and stanford_tags and len(nltk_tags) == len(stanford_tags):\n",
    "            agreements = sum(1 for (_, t1), (_, t2) in zip(nltk_tags, stanford_tags) if t1 == t2)\n",
    "            total_agreements += agreements\n",
    "            total_tokens += len(nltk_tags)\n",
    "            \n",
    "            # Track per-utterance agreement\n",
    "            utterance_pct = (agreements / len(nltk_tags)) * 100\n",
    "            per_utterance_agreements.append(utterance_pct)\n",
    "    \n",
    "    # Overall statistics\n",
    "    overall_agreement_pct = (total_agreements / total_tokens * 100) if total_tokens > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📊 OVERALL STATISTICS:\")\n",
    "    print(f\"   Total tokens compared: {total_tokens}\")\n",
    "    print(f\"   Agreements: {total_agreements}\")\n",
    "    print(f\"   Disagreements: {total_tokens - total_agreements}\")\n",
    "    print(f\"   Overall Agreement: {overall_agreement_pct:.1f}%\")\n",
    "    \n",
    "    if per_utterance_agreements:\n",
    "        import numpy as np\n",
    "        print(f\"\\n   Per-utterance agreement:\")\n",
    "        print(f\"      Mean: {np.mean(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Median: {np.median(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Min: {np.min(per_utterance_agreements):.1f}%\")\n",
    "        print(f\"      Max: {np.max(per_utterance_agreements):.1f}%\")\n",
    "    \n",
    "    # Show detailed examples\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED EXAMPLES (First 3 utterances with >5 words)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    examples_shown = 0\n",
    "    for idx in range(len(results_stanford)):\n",
    "        if examples_shown >= 3:\n",
    "            break\n",
    "            \n",
    "        sample_row = results_stanford.iloc[idx]\n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        stanford_tags = ast.literal_eval(sample_row['tagged_stan_token'])\n",
    "        \n",
    "        if len(nltk_tags) > 5 and len(stanford_tags) > 5:\n",
    "            examples_shown += 1\n",
    "            \n",
    "            print(f\"\\n--- Example {examples_shown} ---\")\n",
    "            print(f\"Source: {sample_row.get('file', 'unknown')}\")\n",
    "            print(f\"Participant: {sample_row.get('participant', 'unknown')}\")\n",
    "            print(f\"Utterance: {sample_row['content']}\\n\")\n",
    "            print(f\"{'Word':<15} {'NLTK':<10} {'Stanford':<10} {'Match':<8}\")\n",
    "            print(\"-\" * 48)\n",
    "            \n",
    "            agreements = 0\n",
    "            disagreements = []\n",
    "            \n",
    "            for (word_n, tag_n), (word_s, tag_s) in zip(nltk_tags, stanford_tags):\n",
    "                match = \"✓\" if tag_n == tag_s else \"✗\"\n",
    "                print(f\"{word_n:<15} {tag_n:<10} {tag_s:<10} {match:<8}\")\n",
    "                \n",
    "                if tag_n == tag_s:\n",
    "                    agreements += 1\n",
    "                else:\n",
    "                    disagreements.append((word_n, tag_n, tag_s))\n",
    "            \n",
    "            total = len(nltk_tags)\n",
    "            print(f\"\\nAgreement: {agreements}/{total} ({100*agreements/total:.1f}%)\")\n",
    "            \n",
    "            if disagreements:\n",
    "                print(f\"Disagreements: {len(disagreements)}\")\n",
    "                for word, nltk_tag, stanford_tag in disagreements[:3]:\n",
    "                    print(f\"  • '{word}': NLTK={nltk_tag}, Stanford={stanford_tag}\")\n",
    "    \n",
    "    # Identify most common disagreements\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MOST COMMON TAG DISAGREEMENTS (NLTK vs Stanford)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    disagreement_counts = {}\n",
    "    for idx in range(len(results_stanford)):\n",
    "        sample_row = results_stanford.iloc[idx]\n",
    "        nltk_tags = ast.literal_eval(sample_row['tagged_token'])\n",
    "        stanford_tags = ast.literal_eval(sample_row['tagged_stan_token'])\n",
    "        \n",
    "        if nltk_tags and stanford_tags:\n",
    "            for (word, t1), (_, t2) in zip(nltk_tags, stanford_tags):\n",
    "                if t1 != t2:\n",
    "                    key = f\"NLTK:{t1} vs Stanford:{t2}\"\n",
    "                    if key not in disagreement_counts:\n",
    "                        disagreement_counts[key] = []\n",
    "                    disagreement_counts[key].append(word)\n",
    "    \n",
    "    # Show top 10 disagreements\n",
    "    if disagreement_counts:\n",
    "        sorted_disagreements = sorted(disagreement_counts.items(), \n",
    "                                     key=lambda x: len(x[1]), \n",
    "                                     reverse=True)\n",
    "        \n",
    "        print(\"\\nTop 10 tag disagreement patterns:\")\n",
    "        for i, (pattern, words) in enumerate(sorted_disagreements[:10], 1):\n",
    "            example_words = ', '.join(list(set(words))[:3])\n",
    "            print(f\"{i:2}. {pattern:<35} (n={len(words):3}) Examples: {example_words}\")\n",
    "    else:\n",
    "        print(\"\\n✓ Perfect agreement! No disagreements found.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare spaCy tags vs Stanford tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPREHENSIVE COMPARISON: spaCy vs Stanford POS Tags\n",
      "============================================================\n",
      "\n",
      "Files in spaCy results: 20\n",
      "Files in Stanford results: 20\n",
      "Files in common: 20\n",
      "\n",
      "📊 OVERALL STATISTICS:\n",
      "   Total tokens compared: 21927\n",
      "   Agreements: 20337\n",
      "   Disagreements: 1590\n",
      "   Overall Agreement: 92.7%\n",
      "\n",
      "   Per-utterance agreement:\n",
      "      Mean: 91.7%\n",
      "      Median: 97.3%\n",
      "      Min: 0.0%\n",
      "      Max: 100.0%\n",
      "\n",
      "============================================================\n",
      "DETAILED EXAMPLES (First 3 utterances with >5 words)\n",
      "============================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "Source: time191-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: my legs are too tired for to walk all the way over there\n",
      "\n",
      "Word            spaCy      Stanford   Match   \n",
      "------------------------------------------------\n",
      "my              PRP$       PRP$       ✓       \n",
      "legs            NNS        NNS        ✓       \n",
      "are             VBP        VBP        ✓       \n",
      "too             RB         RB         ✓       \n",
      "tired           JJ         JJ         ✓       \n",
      "for             IN         IN         ✓       \n",
      "to              TO         TO         ✓       \n",
      "walk            VB         VB         ✓       \n",
      "all             PDT        PDT        ✓       \n",
      "the             DT         DT         ✓       \n",
      "way             NN         NN         ✓       \n",
      "over            RB         IN         ✗       \n",
      "there           RB         RB         ✓       \n",
      "\n",
      "Agreement: 12/13 (92.3%)\n",
      "Disagreements: 1\n",
      "  • 'over': spaCy=RB, Stanford=IN\n",
      "\n",
      "--- Example 2 ---\n",
      "Source: time191-cond1.txt\n",
      "Participant: cgv\n",
      "Utterance:  what are you thinking about well do you want to take a nap how come do you want to throw this ball around\n",
      "\n",
      "Word            spaCy      Stanford   Match   \n",
      "------------------------------------------------\n",
      "what            WP         WP         ✓       \n",
      "are             VBP        VBP        ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "thinking        VBG        VBG        ✓       \n",
      "about           IN         RB         ✗       \n",
      "well            UH         RB         ✗       \n",
      "do              VBP        VBP        ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "want            VB         VB         ✓       \n",
      "to              TO         TO         ✓       \n",
      "take            VB         VB         ✓       \n",
      "a               DT         DT         ✓       \n",
      "nap             NN         NN         ✓       \n",
      "how             WRB        WRB        ✓       \n",
      "come            VB         VBN        ✗       \n",
      "do              VBP        VBP        ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "want            VB         VB         ✓       \n",
      "to              TO         TO         ✓       \n",
      "throw           VB         VB         ✓       \n",
      "this            DT         DT         ✓       \n",
      "ball            NN         NN         ✓       \n",
      "around          RB         IN         ✗       \n",
      "\n",
      "Agreement: 19/23 (82.6%)\n",
      "Disagreements: 4\n",
      "  • 'about': spaCy=IN, Stanford=RB\n",
      "  • 'well': spaCy=UH, Stanford=RB\n",
      "  • 'come': spaCy=VB, Stanford=VBN\n",
      "\n",
      "--- Example 3 ---\n",
      "Source: time191-cond1.txt\n",
      "Participant: kid\n",
      "Utterance: don't kick it over here dad you could just throw it\n",
      "\n",
      "Word            spaCy      Stanford   Match   \n",
      "------------------------------------------------\n",
      "do              VBP        VB         ✗       \n",
      "not             RB         RB         ✓       \n",
      "kick            VB         VB         ✓       \n",
      "it              PRP        PRP        ✓       \n",
      "over            RP         IN         ✗       \n",
      "here            RB         RB         ✓       \n",
      "dad             NN         NN         ✓       \n",
      "you             PRP        PRP        ✓       \n",
      "could           MD         MD         ✓       \n",
      "just            RB         RB         ✓       \n",
      "throw           VB         VB         ✓       \n",
      "it              PRP        PRP        ✓       \n",
      "\n",
      "Agreement: 10/12 (83.3%)\n",
      "Disagreements: 2\n",
      "  • 'do': spaCy=VBP, Stanford=VB\n",
      "  • 'over': spaCy=RP, Stanford=IN\n",
      "\n",
      "============================================================\n",
      "MOST COMMON TAG DISAGREEMENTS (spaCy vs Stanford)\n",
      "============================================================\n",
      "\n",
      "Top 10 tag disagreement patterns:\n",
      " 1. spaCy:NNP vs Stanford:NN            (n=141) Examples: scab, bread, wah\n",
      " 2. spaCy:UH vs Stanford:JJ             (n=118) Examples: sorry, okay, hey\n",
      " 3. spaCy:VB vs Stanford:VBP            (n= 90) Examples: see, play, drink\n",
      " 4. spaCy:UH vs Stanford:DT             (n= 87) Examples: no\n",
      " 5. spaCy:RB vs Stanford:JJ             (n= 61) Examples: straight, yucky, much\n",
      " 6. spaCy:RB vs Stanford:IN             (n= 59) Examples: around, down, outside\n",
      " 7. spaCy:VBP vs Stanford:VB            (n= 53) Examples: see, get, drink\n",
      " 8. spaCy:JJ vs Stanford:NN             (n= 52) Examples: ant, oven, karate\n",
      " 9. spaCy:VB vs Stanford:NN             (n= 51) Examples: get, play, guess\n",
      "10. spaCy:DT vs Stanford:WDT            (n= 48) Examples: that\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COMPARISON: spaCy vs Stanford POS Tags\n",
    "# ============================================================\n",
    "if results_spacy is not None and results_stanford is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPREHENSIVE COMPARISON: spaCy vs Stanford POS Tags\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # First, verify we're comparing the same files\n",
    "    spacy_files = set(results_spacy['file'].unique())\n",
    "    stanford_files = set(results_stanford['file'].unique())\n",
    "    common_files = spacy_files & stanford_files\n",
    "    \n",
    "    print(f\"\\nFiles in spaCy results: {len(spacy_files)}\")\n",
    "    print(f\"Files in Stanford results: {len(stanford_files)}\")\n",
    "    print(f\"Files in common: {len(common_files)}\")\n",
    "    \n",
    "    if not common_files:\n",
    "        print(\"\\n✗ No common files found! Cannot compare.\")\n",
    "    else:\n",
    "        total_agreements = 0\n",
    "        total_tokens = 0\n",
    "        per_utterance_agreements = []\n",
    "        \n",
    "        # Process each file that appears in both results\n",
    "        for file_name in sorted(common_files):\n",
    "            spacy_data = results_spacy[results_spacy['file'] == file_name].reset_index(drop=True)\n",
    "            stanford_data = results_stanford[results_stanford['file'] == file_name].reset_index(drop=True)\n",
    "            \n",
    "            # Compare row by row\n",
    "            for idx in range(min(len(spacy_data), len(stanford_data))):\n",
    "                spacy_tags = ast.literal_eval(spacy_data.iloc[idx]['tagged_spacy_token'])\n",
    "                stanford_tags = ast.literal_eval(stanford_data.iloc[idx]['tagged_stan_token'])\n",
    "                \n",
    "                if spacy_tags and stanford_tags and len(spacy_tags) == len(stanford_tags):\n",
    "                    agreements = sum(1 for (_, t1), (_, t2) in zip(spacy_tags, stanford_tags) if t1 == t2)\n",
    "                    total_agreements += agreements\n",
    "                    total_tokens += len(spacy_tags)\n",
    "                    \n",
    "                    # Track per-utterance agreement\n",
    "                    utterance_pct = (agreements / len(spacy_tags)) * 100\n",
    "                    per_utterance_agreements.append(utterance_pct)\n",
    "        \n",
    "        # Overall statistics\n",
    "        overall_agreement_pct = (total_agreements / total_tokens * 100) if total_tokens > 0 else 0\n",
    "        \n",
    "        print(f\"\\n📊 OVERALL STATISTICS:\")\n",
    "        print(f\"   Total tokens compared: {total_tokens}\")\n",
    "        print(f\"   Agreements: {total_agreements}\")\n",
    "        print(f\"   Disagreements: {total_tokens - total_agreements}\")\n",
    "        print(f\"   Overall Agreement: {overall_agreement_pct:.1f}%\")\n",
    "        \n",
    "        if per_utterance_agreements:\n",
    "            import numpy as np\n",
    "            print(f\"\\n   Per-utterance agreement:\")\n",
    "            print(f\"      Mean: {np.mean(per_utterance_agreements):.1f}%\")\n",
    "            print(f\"      Median: {np.median(per_utterance_agreements):.1f}%\")\n",
    "            print(f\"      Min: {np.min(per_utterance_agreements):.1f}%\")\n",
    "            print(f\"      Max: {np.max(per_utterance_agreements):.1f}%\")\n",
    "        \n",
    "        # Show detailed examples\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DETAILED EXAMPLES (First 3 utterances with >5 words)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        examples_shown = 0\n",
    "        for file_name in sorted(common_files):\n",
    "            if examples_shown >= 3:\n",
    "                break\n",
    "                \n",
    "            spacy_data = results_spacy[results_spacy['file'] == file_name].reset_index(drop=True)\n",
    "            stanford_data = results_stanford[results_stanford['file'] == file_name].reset_index(drop=True)\n",
    "            \n",
    "            for idx in range(min(len(spacy_data), len(stanford_data))):\n",
    "                if examples_shown >= 3:\n",
    "                    break\n",
    "                    \n",
    "                spacy_row = spacy_data.iloc[idx]\n",
    "                stanford_row = stanford_data.iloc[idx]\n",
    "                \n",
    "                spacy_tags = ast.literal_eval(spacy_row['tagged_spacy_token'])\n",
    "                stanford_tags = ast.literal_eval(stanford_row['tagged_stan_token'])\n",
    "                \n",
    "                if len(spacy_tags) > 5 and len(stanford_tags) > 5:\n",
    "                    examples_shown += 1\n",
    "                    \n",
    "                    print(f\"\\n--- Example {examples_shown} ---\")\n",
    "                    print(f\"Source: {spacy_row.get('file', 'unknown')}\")\n",
    "                    print(f\"Participant: {spacy_row.get('participant', 'unknown')}\")\n",
    "                    print(f\"Utterance: {spacy_row['content']}\\n\")\n",
    "                    print(f\"{'Word':<15} {'spaCy':<10} {'Stanford':<10} {'Match':<8}\")\n",
    "                    print(\"-\" * 48)\n",
    "                    \n",
    "                    agreements = 0\n",
    "                    disagreements = []\n",
    "                    \n",
    "                    for (word_s, tag_s), (word_st, tag_st) in zip(spacy_tags, stanford_tags):\n",
    "                        match = \"✓\" if tag_s == tag_st else \"✗\"\n",
    "                        print(f\"{word_s:<15} {tag_s:<10} {tag_st:<10} {match:<8}\")\n",
    "                        \n",
    "                        if tag_s == tag_st:\n",
    "                            agreements += 1\n",
    "                        else:\n",
    "                            disagreements.append((word_s, tag_s, tag_st))\n",
    "                    \n",
    "                    total = len(spacy_tags)\n",
    "                    print(f\"\\nAgreement: {agreements}/{total} ({100*agreements/total:.1f}%)\")\n",
    "                    \n",
    "                    if disagreements:\n",
    "                        print(f\"Disagreements: {len(disagreements)}\")\n",
    "                        for word, spacy_tag, stanford_tag in disagreements[:3]:\n",
    "                            print(f\"  • '{word}': spaCy={spacy_tag}, Stanford={stanford_tag}\")\n",
    "        \n",
    "        # Identify most common disagreements\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MOST COMMON TAG DISAGREEMENTS (spaCy vs Stanford)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        disagreement_counts = {}\n",
    "        for file_name in common_files:\n",
    "            spacy_data = results_spacy[results_spacy['file'] == file_name].reset_index(drop=True)\n",
    "            stanford_data = results_stanford[results_stanford['file'] == file_name].reset_index(drop=True)\n",
    "            \n",
    "            for idx in range(min(len(spacy_data), len(stanford_data))):\n",
    "                spacy_tags = ast.literal_eval(spacy_data.iloc[idx]['tagged_spacy_token'])\n",
    "                stanford_tags = ast.literal_eval(stanford_data.iloc[idx]['tagged_stan_token'])\n",
    "                \n",
    "                if spacy_tags and stanford_tags:\n",
    "                    for (word, t1), (_, t2) in zip(spacy_tags, stanford_tags):\n",
    "                        if t1 != t2:\n",
    "                            key = f\"spaCy:{t1} vs Stanford:{t2}\"\n",
    "                            if key not in disagreement_counts:\n",
    "                                disagreement_counts[key] = []\n",
    "                            disagreement_counts[key].append(word)\n",
    "        \n",
    "        # Show top 10 disagreements\n",
    "        if disagreement_counts:\n",
    "            sorted_disagreements = sorted(disagreement_counts.items(), \n",
    "                                         key=lambda x: len(x[1]), \n",
    "                                         reverse=True)\n",
    "            \n",
    "            print(\"\\nTop 10 tag disagreement patterns:\")\n",
    "            for i, (pattern, words) in enumerate(sorted_disagreements[:10], 1):\n",
    "                example_words = ', '.join(list(set(words))[:3])\n",
    "                print(f\"{i:2}. {pattern:<35} (n={len(words):3}) Examples: {example_words}\")\n",
    "        else:\n",
    "            print(\"\\n✓ Perfect agreement! No disagreements found.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 3: Integration with Alignment Analysis\n",
    "\n",
    "Test that preprocessed files work correctly with the alignment analysis scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Integration with Alignment Analysis\n",
      "============================================================\n",
      "\n",
      "✓ Successfully imported LinguisticAlignment\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 3: Integration with Alignment Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Import alignment analyzer\n",
    "from align_test.alignment import LinguisticAlignment\n",
    "\n",
    "print(\"\\n✓ Successfully imported LinguisticAlignment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing alignment analyzer...\n",
      "✓ Analyzer initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize alignment analyzer\n",
    "print(\"Initializing alignment analyzer...\")\n",
    "\n",
    "analyzer = LinguisticAlignment(\n",
    "    alignment_type=\"lexsyn\",\n",
    "    cache_dir=os.path.join(OUTPUT_DIR_ALIGNMENT, \"cache\")\n",
    ")\n",
    "\n",
    "print(\"✓ Analyzer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running alignment analysis...\n",
      "Input folder: ./test_output_basic\n",
      "Output folder: ./test_alignment_results\n",
      "ANALYZE_FOLDER: Processing data from folder: ./test_output_basic with lag=1\n",
      "Found 22 files to process with lag 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing time197-cond1.txt: 100%|██████████| 76/76 [00:00<00:00, 4584.14it/s]\n",
      "Processing time202-cond1.txt: 100%|██████████| 92/92 [00:00<00:00, 5419.99it/s]\n",
      "Processing time191-cond1.txt: 100%|██████████| 99/99 [00:00<00:00, 6343.26it/s]\n",
      "Processing time209-cond1.txt: 100%|██████████| 98/98 [00:00<00:00, 6174.39it/s]\n",
      "Processing time210-cond1.txt: 100%|██████████| 100/100 [00:00<00:00, 6840.25it/s]\n",
      "Processing time204-cond1.txt: 100%|██████████| 143/143 [00:00<00:00, 5800.52it/s]\n",
      "Processing time192-cond1-bs.txt: 100%|██████████| 67/67 [00:00<00:00, 6614.69it/s]\n",
      "Processing time196-cond1.txt: 100%|██████████| 66/66 [00:00<00:00, 6632.58it/s]\n",
      "Processing time203-cond1.txt: 100%|██████████| 90/90 [00:00<00:00, 6416.25it/s]\n",
      "Processing time208-cond1.txt: 100%|██████████| 86/86 [00:00<00:00, 6025.39it/s]\n",
      "Processing time205-cond1.txt: 100%|██████████| 106/106 [00:00<00:00, 6352.19it/s]\n",
      "Processing time195-cond1.txt: 100%|██████████| 90/90 [00:00<00:00, 6334.53it/s]\n",
      "Processing time198-cond1.txt: 100%|██████████| 89/89 [00:00<00:00, 6584.23it/s]\n",
      "Processing time200-cond1.txt: 100%|██████████| 78/78 [00:00<00:00, 6116.55it/s]\n",
      "Processing time193-cond1.txt: 100%|██████████| 95/95 [00:00<00:00, 6547.68it/s]\n",
      "Processing time206-cond1.txt: 100%|██████████| 97/97 [00:00<00:00, 6439.60it/s]\n",
      "Processing time194-cond1.txt: 100%|██████████| 77/77 [00:00<00:00, 6587.96it/s]\n",
      "Processing time199-cond1.txt: 100%|██████████| 87/87 [00:00<00:00, 6281.71it/s]\n",
      "Processing align_concatenated_dataframe.txt: 100%|██████████| 1832/1832 [00:00<00:00, 6242.14it/s]\n",
      "Processing time201-cond1.txt: 100%|██████████| 90/90 [00:00<00:00, 6568.31it/s]\n",
      "Processing time192-cond1.txt: 100%|██████████| 67/67 [00:00<00:00, 6700.65it/s]\n",
      "Processing time207-cond1.txt: 100%|██████████| 106/106 [00:00<00:00, 6467.42it/s]\n",
      "Processing files with lexsyn: 100%|██████████| 22/22 [00:01<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 22 out of 22 files\n",
      "Results saved to ./test_alignment_results/lexsyn/lexsyn_alignment_ngram2_lag1_noDups_noStan.csv\n",
      "\n",
      "✓ Alignment analysis complete!\n",
      "Utterance pairs analyzed: 3731\n"
     ]
    }
   ],
   "source": [
    "# Run alignment analysis on preprocessed data\n",
    "print(\"\\nRunning alignment analysis...\")\n",
    "print(f\"Input folder: {OUTPUT_DIR_BASIC}\")\n",
    "print(f\"Output folder: {OUTPUT_DIR_ALIGNMENT}\")\n",
    "\n",
    "alignment_results = analyzer.analyze_folder(\n",
    "    folder_path=OUTPUT_DIR_BASIC,\n",
    "    output_directory=OUTPUT_DIR_ALIGNMENT,\n",
    "    lag=1,\n",
    "    max_ngram=2,\n",
    "    ignore_duplicates=True,\n",
    "    add_stanford_tags=False  # Using NLTK-only preprocessed data\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Alignment analysis complete!\")\n",
    "print(f\"Utterance pairs analyzed: {len(alignment_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment Results:\n",
      "Shape: (3731, 24)\n",
      "\n",
      "Columns: ['time', 'source_file', 'participant', 'content', 'token', 'lemma', 'tagged_token', 'tagged_lemma', 'lag', 'utter_order', 'content1', 'content2', 'utterance_length1', 'utterance_length2', 'lexical_tok1_cosine', 'lexical_lem1_cosine', 'pos_tok1_cosine', 'pos_lem1_cosine', 'lexical_tok2_cosine', 'lexical_lem2_cosine', 'pos_tok2_cosine', 'pos_lem2_cosine', 'lexical_master_cosine', 'syntactic_master_cosine']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>source_file</th>\n",
       "      <th>participant</th>\n",
       "      <th>content</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tagged_token</th>\n",
       "      <th>tagged_lemma</th>\n",
       "      <th>lag</th>\n",
       "      <th>utter_order</th>\n",
       "      <th>...</th>\n",
       "      <th>lexical_tok1_cosine</th>\n",
       "      <th>lexical_lem1_cosine</th>\n",
       "      <th>pos_tok1_cosine</th>\n",
       "      <th>pos_lem1_cosine</th>\n",
       "      <th>lexical_tok2_cosine</th>\n",
       "      <th>lexical_lem2_cosine</th>\n",
       "      <th>pos_tok2_cosine</th>\n",
       "      <th>pos_lem2_cosine</th>\n",
       "      <th>lexical_master_cosine</th>\n",
       "      <th>syntactic_master_cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>cgv</td>\n",
       "      <td>that was fun</td>\n",
       "      <td>[that, was, fun]</td>\n",
       "      <td>[that, be, fun]</td>\n",
       "      <td>[(that, DT), (was, VBD), (fun, NN)]</td>\n",
       "      <td>[(that, DT), (be, VB), (fun, NN)]</td>\n",
       "      <td>1</td>\n",
       "      <td>cgv kid</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.696311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>kid</td>\n",
       "      <td>dad you should have climbed the cliffs with us</td>\n",
       "      <td>[dad, you, should, have, climbed, the, cliffs,...</td>\n",
       "      <td>[dad, you, should, have, climb, the, cliff, wi...</td>\n",
       "      <td>[(dad, NN), (you, PRP), (should, MD), (have, V...</td>\n",
       "      <td>[(dad, NN), (you, PRP), (should, MD), (have, V...</td>\n",
       "      <td>1</td>\n",
       "      <td>kid cgv</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369274</td>\n",
       "      <td>0.738549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>cgv</td>\n",
       "      <td>next time i will</td>\n",
       "      <td>[next, time, i, will]</td>\n",
       "      <td>[next, time, i, will]</td>\n",
       "      <td>[(next, JJ), (time, NN), (i, NN), (will, MD)]</td>\n",
       "      <td>[(next, JJ), (time, NN), (i, NN), (will, MD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>cgv kid</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138675</td>\n",
       "      <td>0.077152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>kid</td>\n",
       "      <td>did you have fun fishing i hope that we go the...</td>\n",
       "      <td>[did, you, have, fun, fishing, i, hope, that, ...</td>\n",
       "      <td>[do, you, have, fun, fishing, i, hope, that, w...</td>\n",
       "      <td>[(did, VBD), (you, PRP), (have, VBP), (fun, VB...</td>\n",
       "      <td>[(do, VBP), (you, PRP), (have, VB), (fun, VBN)...</td>\n",
       "      <td>1</td>\n",
       "      <td>kid cgv</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>time197-cond1.txt</td>\n",
       "      <td>cgv</td>\n",
       "      <td>i bet we will</td>\n",
       "      <td>[i, bet, we, will]</td>\n",
       "      <td>[i, bet, we, will]</td>\n",
       "      <td>[(i, JJ), (bet, NN), (we, PRP), (will, MD)]</td>\n",
       "      <td>[(i, JJ), (bet, NN), (we, PRP), (will, MD)]</td>\n",
       "      <td>1</td>\n",
       "      <td>cgv kid</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176777</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.371391</td>\n",
       "      <td>0.533745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.09245</td>\n",
       "      <td>0.085861</td>\n",
       "      <td>0.101781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        source_file participant  \\\n",
       "0     1  time197-cond1.txt         cgv   \n",
       "1     2  time197-cond1.txt         kid   \n",
       "2     3  time197-cond1.txt         cgv   \n",
       "3     4  time197-cond1.txt         kid   \n",
       "4     5  time197-cond1.txt         cgv   \n",
       "\n",
       "                                             content  \\\n",
       "0                                       that was fun   \n",
       "1     dad you should have climbed the cliffs with us   \n",
       "2                                   next time i will   \n",
       "3  did you have fun fishing i hope that we go the...   \n",
       "4                                      i bet we will   \n",
       "\n",
       "                                               token  \\\n",
       "0                                   [that, was, fun]   \n",
       "1  [dad, you, should, have, climbed, the, cliffs,...   \n",
       "2                              [next, time, i, will]   \n",
       "3  [did, you, have, fun, fishing, i, hope, that, ...   \n",
       "4                                 [i, bet, we, will]   \n",
       "\n",
       "                                               lemma  \\\n",
       "0                                    [that, be, fun]   \n",
       "1  [dad, you, should, have, climb, the, cliff, wi...   \n",
       "2                              [next, time, i, will]   \n",
       "3  [do, you, have, fun, fishing, i, hope, that, w...   \n",
       "4                                 [i, bet, we, will]   \n",
       "\n",
       "                                        tagged_token  \\\n",
       "0                [(that, DT), (was, VBD), (fun, NN)]   \n",
       "1  [(dad, NN), (you, PRP), (should, MD), (have, V...   \n",
       "2      [(next, JJ), (time, NN), (i, NN), (will, MD)]   \n",
       "3  [(did, VBD), (you, PRP), (have, VBP), (fun, VB...   \n",
       "4        [(i, JJ), (bet, NN), (we, PRP), (will, MD)]   \n",
       "\n",
       "                                        tagged_lemma  lag utter_order  ...  \\\n",
       "0                  [(that, DT), (be, VB), (fun, NN)]    1     cgv kid  ...   \n",
       "1  [(dad, NN), (you, PRP), (should, MD), (have, V...    1     kid cgv  ...   \n",
       "2      [(next, JJ), (time, NN), (i, NN), (will, MD)]    1     cgv kid  ...   \n",
       "3  [(do, VBP), (you, PRP), (have, VB), (fun, VBN)...    1     kid cgv  ...   \n",
       "4        [(i, JJ), (bet, NN), (we, PRP), (will, MD)]    1     cgv kid  ...   \n",
       "\n",
       "  lexical_tok1_cosine lexical_lem1_cosine  pos_tok1_cosine  pos_lem1_cosine  \\\n",
       "0            0.000000            0.000000         0.522233         0.696311   \n",
       "1            0.000000            0.000000         0.369274         0.738549   \n",
       "2            0.277350            0.277350         0.000000         0.000000   \n",
       "3            0.277350            0.277350         0.353553         0.258199   \n",
       "4            0.176777            0.166667         0.371391         0.533745   \n",
       "\n",
       "   lexical_tok2_cosine  lexical_lem2_cosine  pos_tok2_cosine  pos_lem2_cosine  \\\n",
       "0                  0.0                  0.0         0.000000          0.00000   \n",
       "1                  0.0                  0.0         0.000000          0.00000   \n",
       "2                  0.0                  0.0         0.154303          0.00000   \n",
       "3                  0.0                  0.0         0.000000          0.00000   \n",
       "4                  0.0                  0.0         0.111111          0.09245   \n",
       "\n",
       "   lexical_master_cosine  syntactic_master_cosine  \n",
       "0               0.000000                 0.000000  \n",
       "1               0.000000                 0.000000  \n",
       "2               0.138675                 0.077152  \n",
       "3               0.138675                 0.000000  \n",
       "4               0.085861                 0.101781  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine alignment results\n",
    "print(\"Alignment Results:\")\n",
    "print(f\"Shape: {alignment_results.shape}\")\n",
    "print(f\"\\nColumns: {alignment_results.columns.tolist()}\")\n",
    "\n",
    "alignment_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Alignment Metrics:\n",
      "----------------------------------------\n",
      "✓ lexical_tok1_cosine\n",
      "✓ lexical_lem1_cosine\n",
      "✓ pos_tok1_cosine\n",
      "✓ pos_lem1_cosine\n",
      "✓ lexical_master_cosine\n",
      "✓ syntactic_master_cosine\n",
      "\n",
      "Found 6/6 expected metrics\n"
     ]
    }
   ],
   "source": [
    "# Check for expected alignment metrics\n",
    "expected_metrics = [\n",
    "    'lexical_tok1_cosine',\n",
    "    'lexical_lem1_cosine', \n",
    "    'pos_tok1_cosine',\n",
    "    'pos_lem1_cosine',\n",
    "    'lexical_master_cosine',\n",
    "    'syntactic_master_cosine'\n",
    "]\n",
    "\n",
    "print(\"Expected Alignment Metrics:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "found_metrics = []\n",
    "for metric in expected_metrics:\n",
    "    present = metric in alignment_results.columns\n",
    "    status = \"✓\" if present else \"✗\"\n",
    "    print(f\"{status} {metric}\")\n",
    "    if present:\n",
    "        found_metrics.append(metric)\n",
    "\n",
    "print(f\"\\nFound {len(found_metrics)}/{len(expected_metrics)} expected metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Alignment Scores:\n",
      "============================================================\n",
      "Source: time197-cond1.txt\n",
      "Participant: cgv\n",
      "Content: that was fun\n",
      "\n",
      "Alignment Scores:\n",
      "  lexical_tok1_cosine: 0.0000\n",
      "  lexical_lem1_cosine: 0.0000\n",
      "  pos_tok1_cosine: 0.5222\n",
      "  pos_lem1_cosine: 0.6963\n",
      "  lexical_master_cosine: 0.0000\n",
      "  syntactic_master_cosine: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Show sample alignment scores\n",
    "if found_metrics:\n",
    "    print(\"\\nSample Alignment Scores:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sample = alignment_results.iloc[0]\n",
    "    \n",
    "    print(f\"Source: {sample['source_file']}\")\n",
    "    print(f\"Participant: {sample['participant']}\")\n",
    "    print(f\"Content: {sample['content']}\")\n",
    "    print(f\"\\nAlignment Scores:\")\n",
    "    \n",
    "    for metric in found_metrics:\n",
    "        if metric in sample:\n",
    "            value = sample[metric]\n",
    "            print(f\"  {metric}: {value:.4f}\" if pd.notna(value) else f\"  {metric}: NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 3 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 3 SUMMARY: Alignment Integration\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test3_passed = len(alignment_results) > 0 and len(found_metrics) >= 4\n",
    "\n",
    "if test3_passed:\n",
    "    print(\"\\n✓ TEST 3 PASSED: Integration with alignment analysis works!\")\n",
    "    print(\"\\nPreprocessed files are fully compatible with alignment analysis.\")\n",
    "    print(f\"Successfully analyzed {len(alignment_results)} utterance pairs.\")\n",
    "else:\n",
    "    print(\"\\n✗ TEST 3 FAILED: Integration issues detected.\")\n",
    "    print(\"Please review the test results above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 4: Check Output Files\n",
    "\n",
    "Verify that the saved output files on disk are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 4: Output Files on Disk\n",
      "============================================================\n",
      "\n",
      "Basic output directory: ./test_output_basic\n",
      "Files created: 22\n",
      "  - time197-cond1.txt (41.5 KB)\n",
      "  - time202-cond1.txt (62.5 KB)\n",
      "  - time191-cond1.txt (54.6 KB)\n",
      "  - time209-cond1.txt (61.6 KB)\n",
      "  - time210-cond1.txt (53.5 KB)\n",
      "  - time204-cond1.txt (88.2 KB)\n",
      "  - time192-cond1-bs.txt (40.1 KB)\n",
      "  - time196-cond1.txt (40.4 KB)\n",
      "  - time203-cond1.txt (54.8 KB)\n",
      "  - time208-cond1.txt (64.0 KB)\n",
      "  - time205-cond1.txt (72.4 KB)\n",
      "  - time195-cond1.txt (57.5 KB)\n",
      "  - time198-cond1.txt (53.7 KB)\n",
      "  - time200-cond1.txt (54.9 KB)\n",
      "  - time193-cond1.txt (56.3 KB)\n",
      "  - time206-cond1.txt (62.5 KB)\n",
      "  - time194-cond1.txt (51.8 KB)\n",
      "  - time199-cond1.txt (57.2 KB)\n",
      "  - align_concatenated_dataframe.txt (1145.3 KB)\n",
      "  - time201-cond1.txt (55.6 KB)\n",
      "  - time192-cond1.txt (40.1 KB)\n",
      "  - time207-cond1.txt (63.5 KB)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST 4: Output Files on Disk\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check basic output directory\n",
    "print(f\"\\nBasic output directory: {OUTPUT_DIR_BASIC}\")\n",
    "basic_files = [f for f in os.listdir(OUTPUT_DIR_BASIC) if f.endswith('.txt')]\n",
    "print(f\"Files created: {len(basic_files)}\")\n",
    "for f in basic_files:\n",
    "    size_kb = os.path.getsize(os.path.join(OUTPUT_DIR_BASIC, f)) / 1024\n",
    "    print(f\"  - {f} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying saved file: time197-cond1.txt\n",
      "✓ Loaded 76 rows from disk\n",
      "\n",
      "Token column type: <class 'str'>\n",
      "Token value: ['that', 'was', 'fun']...\n",
      "✓ Successfully parsed to: list\n",
      "  Contents: ['that', 'was', 'fun']\n"
     ]
    }
   ],
   "source": [
    "# Load and verify a saved file\n",
    "if basic_files:\n",
    "    test_file = os.path.join(OUTPUT_DIR_BASIC, basic_files[0])\n",
    "    print(f\"\\nVerifying saved file: {basic_files[0]}\")\n",
    "    \n",
    "    # Load from disk\n",
    "    saved_df = pd.read_csv(test_file, sep='\\t', encoding='utf-8')\n",
    "    print(f\"✓ Loaded {len(saved_df)} rows from disk\")\n",
    "    \n",
    "    # Quick format check\n",
    "    token_str = saved_df['token'].iloc[0]\n",
    "    print(f\"\\nToken column type: {type(token_str)}\")\n",
    "    print(f\"Token value: {token_str[:80]}...\")\n",
    "    \n",
    "    # Parse check\n",
    "    try:\n",
    "        token_list = ast.literal_eval(token_str)\n",
    "        print(f\"✓ Successfully parsed to: {type(token_list).__name__}\")\n",
    "        print(f\"  Contents: {token_list}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Parse failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Summary\n",
    "\n",
    "Overall test results and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL TEST SUMMARY\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test2_passed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Collect results\u001b[39;00m\n\u001b[32m      6\u001b[39m test_results = {\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTEST 1: Basic Preprocessing (NLTK)\u001b[39m\u001b[33m\"\u001b[39m: test1_passed,\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTEST 2: spaCy Integration\u001b[39m\u001b[33m\"\u001b[39m: test2_passed \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtest2_passed\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mSKIPPED\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTEST 3: Alignment Integration\u001b[39m\u001b[33m\"\u001b[39m: test3_passed\n\u001b[32m     10\u001b[39m }\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m test_name, result \u001b[38;5;129;01min\u001b[39;00m test_results.items():\n",
      "\u001b[31mNameError\u001b[39m: name 'test2_passed' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect results\n",
    "test_results = {\n",
    "    \"TEST 1: Basic Preprocessing (NLTK)\": test1_passed,\n",
    "    \"TEST 2: spaCy Integration\": test2_passed if test2_passed is not None else \"SKIPPED\",\n",
    "    \"TEST 3: Alignment Integration\": test3_passed\n",
    "}\n",
    "\n",
    "# Print results\n",
    "for test_name, result in test_results.items():\n",
    "    if result == \"SKIPPED\":\n",
    "        print(f\"⊘ {test_name}: SKIPPED\")\n",
    "    elif result:\n",
    "        print(f\"✓ {test_name}: PASSED\")\n",
    "    else:\n",
    "        print(f\"✗ {test_name}: FAILED\")\n",
    "\n",
    "# Overall assessment\n",
    "passed_tests = [r for r in test_results.values() if r is True]\n",
    "failed_tests = [r for r in test_results.values() if r is False]\n",
    "\n",
    "print(f\"\\nResults: {len(passed_tests)} passed, {len(failed_tests)} failed\")\n",
    "\n",
    "if len(failed_tests) == 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎉 ALL TESTS PASSED!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nThe refactored prepare_transcripts.py is working correctly!\")\n",
    "    print(\"\\nYou can now:\")\n",
    "    print(\"  1. Use prepare_transcripts with your own data\")\n",
    "    print(\"  2. Run alignment analysis on preprocessed output\")\n",
    "    print(\"  3. Generate baseline comparisons with surrogates\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"⚠️  SOME TESTS FAILED\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nPlease review the failed tests above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Quick Preprocessing Example\n",
    "\n",
    "Once tests pass, here's how to preprocess your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Preprocess with spaCy (recommended)\n",
    "# Uncomment and modify paths for your own data\n",
    "\n",
    "# from align_test.prepare_transcripts_refactored import prepare_transcripts\n",
    "\n",
    "# my_results = prepare_transcripts(\n",
    "#     input_files=\"/path/to/my/raw/transcripts\",\n",
    "#     output_file_directory=\"/path/to/my/preprocessed/output\",\n",
    "#     run_spell_check=True,\n",
    "#     minwords=2,\n",
    "#     add_stanford_tags=True,\n",
    "#     stanford_tagger_type='spacy',  # Recommended: fast and accurate\n",
    "#     save_concatenated_dataframe=True\n",
    "# )\n",
    "\n",
    "# print(f\"Preprocessed {len(my_results)} utterances!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Full Pipeline Example\n",
    "\n",
    "Complete workflow from raw data to alignment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Complete pipeline\n",
    "# Uncomment to run on your own data\n",
    "\n",
    "# # Step 1: Preprocess\n",
    "# preprocessed = prepare_transcripts(\n",
    "#     input_files=\"./my_raw_data\",\n",
    "#     output_file_directory=\"./my_preprocessed\",\n",
    "#     add_stanford_tags=True,\n",
    "#     stanford_tagger_type='spacy'\n",
    "# )\n",
    "\n",
    "# # Step 2: Analyze alignment\n",
    "# from align_test.alignment import LinguisticAlignment\n",
    "\n",
    "# analyzer = LinguisticAlignment(alignment_types=[\"lexsyn\", \"fasttext\"])\n",
    "# results = analyzer.analyze_folder(\n",
    "#     folder_path=\"./my_preprocessed\",\n",
    "#     output_directory=\"./my_results\",\n",
    "#     lag=1,\n",
    "#     max_ngram=2,\n",
    "#     add_stanford_tags=True  # Use spaCy tags from preprocessing\n",
    "# )\n",
    "\n",
    "# # Step 3: Generate baseline\n",
    "# baseline = analyzer.analyze_baseline(\n",
    "#     input_files=\"./my_preprocessed\",\n",
    "#     output_directory=\"./my_results\",\n",
    "#     lag=1,\n",
    "#     max_ngram=2,\n",
    "#     add_stanford_tags=True,\n",
    "#     id_separator=\"-\",\n",
    "#     condition_label=\"cond\",\n",
    "#     dyad_label=\"dyad\"\n",
    "# )\n",
    "\n",
    "# print(\"Complete pipeline finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
