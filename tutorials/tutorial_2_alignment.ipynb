{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Tutorial 2: Analyzing Linguistic Alignment\n",
    "\n",
    "This tutorial demonstrates how to analyze linguistic alignment in conversational data using the ALIGN package.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Computing **lexical-syntactic alignment** (word and grammar similarity)\n",
    "- Computing **semantic alignment** using FastText embeddings\n",
    "- Computing **semantic alignment** using BERT embeddings\n",
    "- Comparing different POS taggers (NLTK, spaCy, Stanford)\n",
    "- Using multiple analyzers together for comprehensive analysis\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You should have already:\n",
    "1. Completed Tutorial 1 (Preprocessing)\n",
    "2. Have preprocessed files in `./tutorial_output/preprocessed_nltk/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import and Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the alignment analyzer\n",
    "from align_test.alignment import LinguisticAlignment\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "# Input: Preprocessed data from Tutorial 1\n",
    "INPUT_DIR_NLTK = './tutorial_output/preprocessed_nltk'\n",
    "INPUT_DIR_SPACY = './tutorial_output/preprocessed_spacy'\n",
    "INPUT_DIR_STANFORD = './tutorial_output/preprocessed_stanford'\n",
    "\n",
    "# Output: Where to save alignment results\n",
    "OUTPUT_DIR = './tutorial_output/alignment_results'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Verify input data exists\n",
    "if os.path.exists(INPUT_DIR_NLTK):\n",
    "    files = [f for f in os.listdir(INPUT_DIR_NLTK) if f.endswith('.txt')]\n",
    "    print(f\"‚úì Found {len(files)} preprocessed files\")\n",
    "else:\n",
    "    print(\"‚úó Preprocessed data not found!\")\n",
    "    print(\"Please run Tutorial 1 (Preprocessing) first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lexsyn_intro",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Lexical-Syntactic Alignment\n",
    "\n",
    "This analyzes how speakers align in their **word choices** (lexical) and **grammar patterns** (syntactic).\n",
    "\n",
    "### Key Parameters:\n",
    "- `lag=1`: Compare each utterance with the next one (turn-by-turn)\n",
    "- `max_ngram=2`: Analyze both unigrams (single words) and bigrams (word pairs)\n",
    "- `ignore_duplicates=True`: Ignore repeated n-grams when computing syntactic alignment\n",
    "\n",
    "### Metrics Computed:\n",
    "- **Lexical alignment**: Word overlap between speakers\n",
    "- **Syntactic alignment**: Grammar pattern (POS tag) similarity\n",
    "- **Master scores**: Averaged alignment across n-gram sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lexsyn_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lexical-syntactic analyzer\n",
    "print(\"Initializing analyzer...\\n\")\n",
    "\n",
    "analyzer_lexsyn = LinguisticAlignment(\n",
    "    alignment_type=\"lexsyn\"\n",
    ")\n",
    "\n",
    "print(\"‚úì Analyzer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lexsyn_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run alignment analysis\n",
    "print(\"Analyzing lexical-syntactic alignment...\\n\")\n",
    "\n",
    "results_lexsyn = analyzer_lexsyn.analyze_folder(\n",
    "    folder_path=INPUT_DIR_NLTK,\n",
    "    output_directory=OUTPUT_DIR,\n",
    "    lag=1,\n",
    "    max_ngram=2,\n",
    "    ignore_duplicates=True,\n",
    "    add_additional_tags=False  # Using NLTK tags only\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Analysis complete!\")\n",
    "print(f\"Analyzed {len(results_lexsyn)} utterance pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "examine_lexsyn",
   "metadata": {},
   "source": [
    "### Examine Results\n",
    "\n",
    "Let's look at what alignment metrics were computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lexsyn_examine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all alignment metrics\n",
    "alignment_metrics = [col for col in results_lexsyn.columns if 'cosine' in col]\n",
    "\n",
    "print(\"Alignment Metrics Computed:\\n\")\n",
    "for metric in alignment_metrics:\n",
    "    print(f\"  - {metric}\")\n",
    "\n",
    "print(f\"\\nSample alignment scores (first utterance pair):\")\n",
    "sample = results_lexsyn.iloc[10]\n",
    "print(f\"\\nParticipants: {sample['utter_order']}\")\n",
    "print(f\"Content 1: {sample['content1']}\")\n",
    "print(f\"Content 2: {sample['content2']}\")\n",
    "print(f\"\\nLexical alignment: {sample['lexical_master_cosine']:.4f}\")\n",
    "print(f\"Syntactic alignment: {sample['syntactic_master_cosine']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_lexsyn",
   "metadata": {},
   "source": [
    "### Visualize Alignment Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lexsyn_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Lexical alignment\n",
    "results_lexsyn['lexical_master_cosine'].hist(\n",
    "    ax=axes[0], bins=30, edgecolor='black', alpha=0.7, color='steelblue'\n",
    ")\n",
    "axes[0].set_title('Lexical Alignment Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Lexical Alignment Score', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].axvline(results_lexsyn['lexical_master_cosine'].mean(), \n",
    "                color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Syntactic alignment\n",
    "results_lexsyn['syntactic_master_cosine'].hist(\n",
    "    ax=axes[1], bins=30, edgecolor='black', alpha=0.7, color='coral'\n",
    ")\n",
    "axes[1].set_title('Syntactic Alignment Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Syntactic Alignment Score', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].axvline(results_lexsyn['syntactic_master_cosine'].mean(), \n",
    "                color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nAlignment Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(results_lexsyn[['lexical_master_cosine', 'syntactic_master_cosine']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare_taggers",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Comparing Different POS Taggers (Optional)\n",
    "\n",
    "If you preprocessed with spaCy or Stanford in Tutorial 1, you can compare how different taggers affect alignment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_spacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if spaCy preprocessing is available\n",
    "if os.path.exists(INPUT_DIR_SPACY):\n",
    "    print(\"Analyzing with spaCy tags...\\n\")\n",
    "    \n",
    "    results_spacy = analyzer_lexsyn.analyze_folder(\n",
    "        folder_path=INPUT_DIR_SPACY,\n",
    "        output_directory=OUTPUT_DIR,\n",
    "        lag=1,\n",
    "        max_ngram=2,\n",
    "        ignore_duplicates=True,\n",
    "        add_additional_tags=True,\n",
    "        additional_tagger_type='spacy'\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì spaCy analysis complete!\")\n",
    "    \n",
    "    # Compare syntactic master scores\n",
    "    print(f\"\\nSyntactic Alignment Comparison:\")\n",
    "    print(f\"  NLTK only:  {results_lexsyn['syntactic_master_cosine'].mean():.4f}\")\n",
    "    print(f\"  With spaCy: {results_spacy['syntactic_master_cosine'].mean():.4f}\")\n",
    "    print(f\"\\nNote: spaCy scores include both NLTK and spaCy POS tags (averaged)\")\n",
    "else:\n",
    "    print(\"‚äò spaCy preprocessing not available\")\n",
    "    print(\"Run Tutorial 1 with spaCy option to enable this comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fasttext_intro",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Semantic Alignment with FastText\n",
    "\n",
    "FastText analyzes **semantic similarity** - whether speakers use words with similar meanings, even if the exact words differ.\n",
    "\n",
    "### First Run:\n",
    "- Downloads FastText model (~1-2 GB)\n",
    "- May take several minutes\n",
    "- Model is cached for future use\n",
    "\n",
    "### What It Does:\n",
    "- Converts words to 300-dimensional vectors\n",
    "- Compares vector similarity between utterances\n",
    "- Filters vocabulary to focus on content words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fasttext_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FastText analyzer\n",
    "print(\"Initializing FastText analyzer...\\n\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: First run will download FastText model (~1-2 GB). This may take several minutes...\\n\")\n",
    "\n",
    "analyzer_fasttext = LinguisticAlignment(\n",
    "    alignment_type=\"fasttext\",\n",
    "    cache_dir=os.path.join(OUTPUT_DIR, \"cache\")\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Analyzer ready. Next run will be much faster since the model is cached.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fasttext_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FastText semantic alignment\n",
    "print(\"\\nAnalyzing semantic alignment with FastText...\\n\")\n",
    "\n",
    "results_fasttext = analyzer_fasttext.analyze_folder(\n",
    "    folder_path=INPUT_DIR_NLTK,\n",
    "    output_directory=OUTPUT_DIR,\n",
    "    lag=1,\n",
    "    high_sd_cutoff=3,  # Exclude very common words\n",
    "    low_n_cutoff=1     # Exclude very rare words\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì FastText analysis complete!\")\n",
    "print(f\"Analyzed {len(results_fasttext)} utterance pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fasttext_examine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine FastText metrics\n",
    "fasttext_metrics = [col for col in results_fasttext.columns if 'fasttext' in col and 'cosine' in col]\n",
    "\n",
    "print(\"FastText Metrics Computed:\\n\")\n",
    "for metric in fasttext_metrics:\n",
    "    print(f\"  - {metric}\")\n",
    "\n",
    "# Visualize semantic alignment\n",
    "master_metric = [m for m in fasttext_metrics if 'master' in m.lower()][0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "results_fasttext[master_metric].hist(bins=30, edgecolor='black', alpha=0.7, color='forestgreen')\n",
    "plt.title('FastText Semantic Alignment Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Semantic Similarity Score', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.axvline(results_fasttext[master_metric].mean(), \n",
    "            color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean semantic similarity: {results_fasttext[master_metric].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bert_intro",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Semantic Alignment with BERT (Optional)\n",
    "\n",
    "BERT provides **contextual semantic analysis** - understanding meaning based on surrounding words.\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "#### Get a Hugging Face Token:\n",
    "1. Go to: https://huggingface.co/settings/tokens\n",
    "2. Click 'New token' ‚Üí Copy token\n",
    "3. Set environment variable:\n",
    "\n",
    "**macOS/Linux:**\n",
    "```bash\n",
    "# Add to ~/.zshrc or ~/.bash_profile\n",
    "export HUGGINGFACE_TOKEN='your_token_here'\n",
    "```\n",
    "\n",
    "**Windows:**\n",
    "```bash\n",
    "setx HUGGINGFACE_TOKEN \"your_token_here\"\n",
    "```\n",
    "\n",
    "4. Restart Jupyter for changes to take effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bert_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Hugging Face token\n",
    "token_available = 'HUGGINGFACE_TOKEN' in os.environ\n",
    "\n",
    "if token_available:\n",
    "    print(\"‚úì Hugging Face token found\")\n",
    "    print(\"Ready to use BERT!\")\n",
    "else:\n",
    "    print(\"‚úó Hugging Face token not found\")\n",
    "    print(\"\\nPlease see the setup instructions above.\")\n",
    "    print(\"After setting the token, restart Jupyter and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bert_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "if token_available:\n",
    "    print(\"Initializing BERT analyzer...\\n\")\n",
    "    \n",
    "    analyzer_bert = LinguisticAlignment(\n",
    "        alignment_type=\"bert\",\n",
    "        model_name=\"bert-base-uncased\",\n",
    "        token=os.environ.get('HUGGINGFACE_TOKEN')\n",
    "    )\n",
    "    \n",
    "    print(\"Analyzing semantic alignment with BERT...\\n\")\n",
    "    \n",
    "    results_bert = analyzer_bert.analyze_folder(\n",
    "        folder_path=INPUT_DIR_NLTK,\n",
    "        output_directory=OUTPUT_DIR,\n",
    "        lag=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úì BERT analysis complete!\")\n",
    "    print(f\"Mean semantic similarity: {results_bert['bert-base-uncased_cosine_similarity'].mean():.4f}\")\n",
    "else:\n",
    "    print(\"‚äò Skipping BERT analysis (token not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multi_analyzer",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Multi-Analyzer Comprehensive Analysis\n",
    "\n",
    "You can run **multiple analyzers simultaneously** and get merged results with all metrics in one dataframe.\n",
    "\n",
    "This is useful for:\n",
    "- Comparing lexical vs. semantic alignment\n",
    "- Getting a comprehensive view of all alignment types\n",
    "- Analyzing correlations between different alignment measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize combined analyzer with multiple types\n",
    "print(\"Initializing multi-analyzer (LexSyn + FastText)...\\n\")\n",
    "\n",
    "analyzer_combined = LinguisticAlignment(\n",
    "    alignment_types=[\"lexsyn\", \"fasttext\"],  # List of types\n",
    "    cache_dir=os.path.join(OUTPUT_DIR, \"cache\")\n",
    ")\n",
    "\n",
    "print(\"‚úì Multi-analyzer ready\")\n",
    "print(f\"Will compute both lexical-syntactic AND semantic alignment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run combined analysis\n",
    "print(\"\\nRunning comprehensive multi-analyzer analysis...\\n\")\n",
    "\n",
    "results_combined = analyzer_combined.analyze_folder(\n",
    "    folder_path=INPUT_DIR_NLTK,\n",
    "    output_directory=OUTPUT_DIR,\n",
    "    lag=1,\n",
    "    max_ngram=2,              # For LexSyn\n",
    "    ignore_duplicates=True,   # For LexSyn\n",
    "    high_sd_cutoff=3,         # For FastText\n",
    "    low_n_cutoff=1            # For FastText\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Multi-analyzer analysis complete!\")\n",
    "print(f\"Combined results: {results_combined.shape[0]} rows √ó {results_combined.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi_examine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all metrics in combined results\n",
    "print(\"\\nAll Metrics in Combined Results:\\n\")\n",
    "\n",
    "# Lexical-syntactic metrics\n",
    "lexsyn_metrics = [col for col in results_combined.columns \n",
    "                  if any(x in col for x in ['lexical_', 'syntactic_', 'pos_'])]\n",
    "print(\"Lexical-Syntactic Metrics:\")\n",
    "for m in lexsyn_metrics:\n",
    "    print(f\"  - {m}\")\n",
    "\n",
    "# Semantic metrics\n",
    "semantic_metrics = [col for col in results_combined.columns if 'fasttext' in col]\n",
    "print(f\"\\nSemantic (FastText) Metrics:\")\n",
    "for m in semantic_metrics:\n",
    "    print(f\"  - {m}\")\n",
    "\n",
    "# Show sample scores\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Sample Comprehensive Alignment Scores (First Utterance Pair)\")\n",
    "print(\"=\"*60)\n",
    "sample = results_combined.iloc[10]\n",
    "print(f\"\\nLexical alignment:   {sample['lexical_master_cosine']:.4f}\")\n",
    "print(f\"Syntactic alignment: {sample['syntactic_master_cosine']:.4f}\")\n",
    "if 'master_fasttext-wiki-news-300_cosine_similarity' in sample:\n",
    "    print(f\"Semantic alignment:  {sample['master_fasttext-wiki-news-300_cosine_similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multi_viz",
   "metadata": {},
   "source": [
    "### Compare All Alignment Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi_viz_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Lexical\n",
    "results_combined['lexical_master_cosine'].hist(\n",
    "    ax=axes[0], bins=30, edgecolor='black', alpha=0.7, color='steelblue'\n",
    ")\n",
    "axes[0].set_title('Lexical Alignment', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Score', fontsize=12)\n",
    "axes[0].axvline(results_combined['lexical_master_cosine'].mean(), \n",
    "                color='red', linestyle='--', linewidth=2)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Syntactic\n",
    "results_combined['syntactic_master_cosine'].hist(\n",
    "    ax=axes[1], bins=30, edgecolor='black', alpha=0.7, color='coral'\n",
    ")\n",
    "axes[1].set_title('Syntactic Alignment', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Score', fontsize=12)\n",
    "axes[1].axvline(results_combined['syntactic_master_cosine'].mean(), \n",
    "                color='red', linestyle='--', linewidth=2)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Semantic (FastText)\n",
    "semantic_col = [c for c in results_combined.columns if 'master' in c and 'fasttext' in c][0]\n",
    "results_combined[semantic_col].hist(\n",
    "    ax=axes[2], bins=30, edgecolor='black', alpha=0.7, color='forestgreen'\n",
    ")\n",
    "axes[2].set_title('Semantic Alignment (FastText)', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Score', fontsize=12)\n",
    "axes[2].axvline(results_combined[semantic_col].mean(), \n",
    "                color='red', linestyle='--', linewidth=2)\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nComparative Statistics:\")\n",
    "print(\"=\"*60)\n",
    "summary_cols = ['lexical_master_cosine', 'syntactic_master_cosine', semantic_col]\n",
    "print(results_combined[summary_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correlation",
   "metadata": {},
   "source": [
    "### Analyze Correlations Between Alignment Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations\n",
    "correlation_cols = ['lexical_master_cosine', 'syntactic_master_cosine', semantic_col]\n",
    "correlations = results_combined[correlation_cols].corr()\n",
    "\n",
    "print(\"Correlations Between Alignment Types:\")\n",
    "print(\"=\"*60)\n",
    "print(correlations)\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"Lexical-Syntactic correlation: {correlations.iloc[0,1]:.3f}\")\n",
    "if abs(correlations.iloc[0,1]) > 0.5:\n",
    "    print(\"  ‚Üí Strong relationship: Word similarity often accompanies grammar similarity\")\n",
    "elif abs(correlations.iloc[0,1]) > 0.3:\n",
    "    print(\"  ‚Üí Moderate relationship: Some connection between word and grammar patterns\")\n",
    "else:\n",
    "    print(\"  ‚Üí Weak relationship: Lexical and syntactic alignment are relatively independent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output_files",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Review Output Files\n",
    "\n",
    "All alignment results are saved as CSV files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "output_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "print(\"üìÅ Output Files Created:\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find all output files\n",
    "output_files = glob.glob(os.path.join(OUTPUT_DIR, '**/*.csv'), recursive=True)\n",
    "\n",
    "for file_path in sorted(output_files):\n",
    "    # Get relative path and file size\n",
    "    rel_path = os.path.relpath(file_path, OUTPUT_DIR)\n",
    "    size_kb = os.path.getsize(file_path) / 1024\n",
    "    \n",
    "    # Determine analyzer type from path\n",
    "    if 'lexsyn' in rel_path:\n",
    "        analyzer = \"LexSyn\"\n",
    "    elif 'fasttext' in rel_path:\n",
    "        analyzer = \"FastText\"\n",
    "    elif 'bert' in rel_path:\n",
    "        analyzer = \"BERT\"\n",
    "    elif 'merged' in rel_path:\n",
    "        analyzer = \"Combined\"\n",
    "    else:\n",
    "        analyzer = \"Other\"\n",
    "    \n",
    "    print(f\"{analyzer:10} {rel_path:60} ({size_kb:7.1f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've completed the alignment analysis tutorial.\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "1. ‚úì **Lexical-Syntactic Alignment**: Measuring word and grammar similarity\n",
    "2. ‚úì **Semantic Alignment (FastText)**: Analyzing meaning similarity\n",
    "3. ‚úì **Semantic Alignment (BERT)**: Contextual semantic analysis\n",
    "4. ‚úì **Multi-Analyzer Analysis**: Running multiple analyzers together\n",
    "5. ‚úì **Comparative Analysis**: Understanding relationships between alignment types\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Use your own data**: Replace input paths with your preprocessed conversations\n",
    "- **Adjust parameters**: Experiment with different `lag`, `max_ngram`, and filtering settings\n",
    "- **Generate baselines**: Compare real conversations to surrogate pairs (see documentation)\n",
    "- **Statistical analysis**: Load the CSV files into R, Python, or your preferred tool\n",
    "\n",
    "### Key Metrics Reference:\n",
    "\n",
    "**Lexical-Syntactic:**\n",
    "- `lexical_master_cosine`: Overall word similarity (0-1, higher = more similar)\n",
    "- `syntactic_master_cosine`: Overall grammar similarity (0-1, higher = more similar)\n",
    "\n",
    "**Semantic:**\n",
    "- `master_fasttext-wiki-news-300_cosine_similarity`: Overall meaning similarity\n",
    "- `bert-base-uncased_cosine_similarity`: Contextual semantic similarity\n",
    "\n",
    "### Understanding the Scores:\n",
    "\n",
    "- **0.0**: No alignment (completely different)\n",
    "- **0.3-0.5**: Moderate alignment (some similarity)\n",
    "- **0.7-0.9**: High alignment (strong similarity)\n",
    "- **1.0**: Perfect alignment (identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Tutorial Complete!\n",
    "\n",
    "You now have all the tools to analyze linguistic alignment in conversational data.\n",
    "\n",
    "For more information:\n",
    "- See the README.md for detailed documentation\n",
    "- Check example scripts in the `examples/` folder\n",
    "- Visit the GitHub repository for updates and support"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (align-venv)",
   "language": "python",
   "name": "align-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
